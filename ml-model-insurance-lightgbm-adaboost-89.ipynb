{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"},{"sourceId":7349720,"sourceType":"datasetVersion","datasetId":4268036}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model machine learning - Insurance car","metadata":{}},{"cell_type":"markdown","source":"# Part 1 - Business Problem\n\n\n![](https://img.freepik.com/vetores-gratis/ilustracao-de-seguro-de-vida_53876-5312.jpg?t=st=1721189978~exp=1721193578~hmac=d9370211eaa85efe62462cb028539e787a1a7e74863c505afd3a8cc07cc8a19f&w=740)\n\n\n## Business Problem\n\n**Objective**\n\nPredict which customers will respond positively to an automobile insurance offer using machine learning techniques. This will enable the insurance company to target its marketing campaigns more efficiently, increasing conversion rates and reducing customer acquisition costs.\n\n**Context**\n\nThe insurance company is launching a new campaign to promote its automobile insurance product. The company has historical data on customer characteristics and their responses to previous offers. Based on this data, the company wants to build a predictive model that estimates the likelihood of a customer accepting the insurance offer.\n\n## Expected Impact\n\n- Increased Conversion Rate: Targeting offers to customers more likely to accept will increase the success rate of marketing campaigns.\n\n- Cost Reduction: Focusing on customers with a higher probability of positive response reduces marketing expenses on less likely customers.\n\n- Improved Customer Satisfaction: Customers receiving relevant and personalized offers are more likely to have a positive perception of the company.\n\n## Data Description\n\nThe available data includes demographic and behavioral information about customers, as well as their responses to previous insurance offers. The dataset is synthetic, generated to maintain the privacy of real customer data.\n\n## Variables in the Dataset\n\n**1. id:** Unique identification of the customer.\n\n**2. features:** Various customer characteristics (age, income, response history, etc.).\n\n**3. Response:** Target variable indicating whether the customer responded positively to the insurance offer (1 for yes, 0 for no).\n\n## Challenges\n\n**Synthetic Data:** Although the data is synthetic, it must be representative enough to create reliable predictive models.\n\n**Class Imbalance:** The dataset is likely imbalanced, with more negative than positive responses, requiring appropriate balancing techniques.\n\n**Feature Engineering:** Identifying and creating relevant features to improve model performance.\n\n## Methodology\n\n**1. Exploratory Data Analysis (EDA):** Understand data distribution and identify patterns and anomalies.\n\n**2. Data Preprocessing:** Handle missing values, encode categorical variables, and normalize the data.\n\n**3. Data Splitting:** Separate the data into training and validation sets to evaluate model performance.\n\n**4. Model Training:** Use different machine learning algorithms (RandomForest, XGBoost, LightGBM) and select the best model based on the AUC-ROC metric.\n\n**5. Model Optimization:** Adjust hyperparameters and apply cross-validation techniques.\n\n**6. Model Evaluation:** Use the ROC curve and AUC metric to evaluate model performance.\n\n**7. Submission of Results:** Generate predictions for the test set and submit to Kaggle.\n\n## Evaluation Metric\n\n**AUC-ROC:** The evaluation metric for the competition is the area under the ROC curve, which measures the model's ability to distinguish between classes.\n\n## Conclusion\nAccurately predicting which customers will respond positively to an insurance offer can significantly improve the efficiency of marketing campaigns, reduce costs, and increase customer satisfaction.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-21T05:51:18.781605Z","iopub.execute_input":"2024-07-21T05:51:18.781997Z","iopub.status.idle":"2024-07-21T05:51:18.789838Z","shell.execute_reply.started":"2024-07-21T05:51:18.781941Z","shell.execute_reply":"2024-07-21T05:51:18.788942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Installing packages\n!pip install watermark","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:18.795296Z","iopub.execute_input":"2024-07-21T05:51:18.795654Z","iopub.status.idle":"2024-07-21T05:51:31.006243Z","shell.execute_reply.started":"2024-07-21T05:51:18.795623Z","shell.execute_reply":"2024-07-21T05:51:31.005221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import of libraries\n\n# System libraries\nimport re\nimport unicodedata\nimport itertools\n\n# Library for file manipulation\nimport pandas as pd\nimport numpy as np\nimport pandas\n\n# Data visualization\nimport seaborn as sns\nimport matplotlib.pylab as pl\nimport matplotlib as m\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom matplotlib import pyplot as plt\n\n# Configuration for graph width and layout\nsns.set_theme(style='whitegrid')\npalette='viridis'\n\n# Python version\nfrom platform import python_version\nprint('Python version in this Jupyter Notebook:', python_version())\n\n# Load library versions\nimport watermark\n\n# Library versions\n%reload_ext watermark\n%watermark -a \"Library versions\" --iversions\n\n# Warnings remove alerts\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:31.00823Z","iopub.execute_input":"2024-07-21T05:51:31.008508Z","iopub.status.idle":"2024-07-21T05:51:31.887707Z","shell.execute_reply.started":"2024-07-21T05:51:31.008483Z","shell.execute_reply":"2024-07-21T05:51:31.886821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 2 - Database","metadata":{}},{"cell_type":"code","source":"# Set the display.max_columns option to None\npd.set_option('display.max_columns', None)\n\n## Data 1\n# Data train\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s4e7/train.csv\")\n\n# Data test\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s4e7/test.csv\")\n\n# Data 2\ndf = pd.read_csv(\"/kaggle/input/health-insurance-cross-sell-prediction-data/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:31.888745Z","iopub.execute_input":"2024-07-21T05:51:31.889188Z","iopub.status.idle":"2024-07-21T05:51:57.386Z","shell.execute_reply.started":"2024-07-21T05:51:31.889162Z","shell.execute_reply":"2024-07-21T05:51:57.385187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing first 5 data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:57.388114Z","iopub.execute_input":"2024-07-21T05:51:57.388406Z","iopub.status.idle":"2024-07-21T05:51:57.407367Z","shell.execute_reply.started":"2024-07-21T05:51:57.388379Z","shell.execute_reply":"2024-07-21T05:51:57.406507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing 5 latest data\ntrain_df.tail()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:57.408599Z","iopub.execute_input":"2024-07-21T05:51:57.408875Z","iopub.status.idle":"2024-07-21T05:51:57.423618Z","shell.execute_reply.started":"2024-07-21T05:51:57.408851Z","shell.execute_reply":"2024-07-21T05:51:57.422605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Info data\ntrain_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:57.424609Z","iopub.execute_input":"2024-07-21T05:51:57.425324Z","iopub.status.idle":"2024-07-21T05:51:57.436768Z","shell.execute_reply.started":"2024-07-21T05:51:57.425291Z","shell.execute_reply":"2024-07-21T05:51:57.435816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Type dados\ntrain_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:57.437911Z","iopub.execute_input":"2024-07-21T05:51:57.438237Z","iopub.status.idle":"2024-07-21T05:51:57.447318Z","shell.execute_reply.started":"2024-07-21T05:51:57.438212Z","shell.execute_reply":"2024-07-21T05:51:57.446442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing rows and columns\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:57.448525Z","iopub.execute_input":"2024-07-21T05:51:57.448837Z","iopub.status.idle":"2024-07-21T05:51:57.456903Z","shell.execute_reply.started":"2024-07-21T05:51:57.448812Z","shell.execute_reply":"2024-07-21T05:51:57.455924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3 - Exploratory data analysis","metadata":{}},{"cell_type":"code","source":"# Exploratory data analysis (EDA)\nprint(\"\\nDescriptive statistics of the training set:\")\ntrain_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:51:57.458068Z","iopub.execute_input":"2024-07-21T05:51:57.458393Z","iopub.status.idle":"2024-07-21T05:52:00.774166Z","shell.execute_reply.started":"2024-07-21T05:51:57.458362Z","shell.execute_reply":"2024-07-21T05:52:00.773223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysis of categorical and numerical variables\ncategorical_features = train_df.select_dtypes(include=['object']).columns\nnumerical_features = train_df.select_dtypes(include=[np.number]).columns\n\nprint(\"\\nCategorical Variables:\", categorical_features)\nprint(\"Numeric Variables:\", numerical_features)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:00.777548Z","iopub.execute_input":"2024-07-21T05:52:00.777846Z","iopub.status.idle":"2024-07-21T05:52:01.485388Z","shell.execute_reply.started":"2024-07-21T05:52:00.77782Z","shell.execute_reply":"2024-07-21T05:52:01.484418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analysis of categorical variables\nfor col in categorical_features:\n    print(f\"\\nDistribution of categorical variable {col}:\")\n    print(train_df[col].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:01.486555Z","iopub.execute_input":"2024-07-21T05:52:01.486872Z","iopub.status.idle":"2024-07-21T05:52:06.728945Z","shell.execute_reply.started":"2024-07-21T05:52:01.486844Z","shell.execute_reply":"2024-07-21T05:52:06.728008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3.1 - Analysis of categorical and numeric variable data","metadata":{}},{"cell_type":"code","source":"# Analysis of target variable 'Target'\nprint(\"\\nDistribution of target variable 'Target':\")\nprint(train_df['Response'].value_counts())\nplt.figure(figsize=(10, 6))\nsns.countplot(data=train_df, x='Response')\nplt.title(\"Distribution of Target Variable 'Target'\")\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:06.730465Z","iopub.execute_input":"2024-07-21T05:52:06.730843Z","iopub.status.idle":"2024-07-21T05:52:07.87792Z","shell.execute_reply.started":"2024-07-21T05:52:06.730808Z","shell.execute_reply":"2024-07-21T05:52:07.877034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.boxplot(x='Vehicle_Age', y='Annual_Premium', hue='Response', data=train_df)\nplt.title('Boxplot of Annual Premium by Vehicle Age and Response')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:07.879309Z","iopub.execute_input":"2024-07-21T05:52:07.879661Z","iopub.status.idle":"2024-07-21T05:52:22.90568Z","shell.execute_reply.started":"2024-07-21T05:52:07.879626Z","shell.execute_reply":"2024-07-21T05:52:22.904591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group data by gender and calculate the total annual premium for each group\ntotal_premium_by_gender = train_df.groupby('Gender')['Annual_Premium'].sum().reset_index()\n\n# View total prize by gender\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Gender', y='Annual_Premium', data=total_premium_by_gender)\nplt.title('Total Prize for Sex')\nplt.xlabel('Sex')\nplt.ylabel('Annual Premium Total')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:22.906908Z","iopub.execute_input":"2024-07-21T05:52:22.907263Z","iopub.status.idle":"2024-07-21T05:52:24.281539Z","shell.execute_reply.started":"2024-07-21T05:52:22.907235Z","shell.execute_reply":"2024-07-21T05:52:24.280611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create age ranges\ntrain_df['Age_Bucket'] = pd.cut(train_df['Age'], bins=[18, 25, 35, 50, np.inf], labels=['18-25', '26-35', ' 36-50', '51+'])\n\n# Group data by age group and gender, and calculate the average annual premium for each group\naverage_premium_by_age_gender = train_df.groupby(['Age_Bucket', 'Gender'])['Annual_Premium'].mean().reset_index()\n\n# View the average annual premium by age group and gender\nplt.figure(figsize=(20, 10))\nsns.barplot(x='Age_Bucket', y='Annual_Premium', hue='Gender', data=average_premium_by_age_gender)\nplt.title('Average Annual Award by Age Group and Sex')\nplt.xlabel('Age Range')\nplt.ylabel('Average Annual Premium')\nplt.legend(title='Sex')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:24.282823Z","iopub.execute_input":"2024-07-21T05:52:24.283189Z","iopub.status.idle":"2024-07-21T05:52:26.347342Z","shell.execute_reply.started":"2024-07-21T05:52:24.283152Z","shell.execute_reply":"2024-07-21T05:52:26.346424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group data by gender and previous insurance status, and calculate the average annual premium for each group\naverage_premium_by_gender_insured = train_df.groupby(['Gender', 'Previously_Insured'])['Annual_Premium'].mean().reset_index()\n\n# Transform the 'Previously_Insured' variable into a more readable category\naverage_premium_by_gender_insured['Previously_Insured'] = average_premium_by_gender_insured['Previously_Insured'].map({0: 'No', 1: 'Yes'})\n\n# View average annual premium by gender and previous insurance status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Previously_Insured', y='Annual_Premium', hue='Gender', data=average_premium_by_gender_insured)\nplt.title('Average Annual Premium by Previous Insurance Status and Gender')\nplt.xlabel('Previous Insurance')\nplt.ylabel('Average Annual Premium')\nplt.legend(title='Sex')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:26.348635Z","iopub.execute_input":"2024-07-21T05:52:26.34894Z","iopub.status.idle":"2024-07-21T05:52:28.17743Z","shell.execute_reply.started":"2024-07-21T05:52:26.348911Z","shell.execute_reply":"2024-07-21T05:52:28.176487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical variables to iterate\ncategorical_variables = ['Gender', 'Vehicle_Damage', 'Vehicle_Age', 'Response']\n\n# Figure size\nplt.figure(figsize=(15, 10))\n\n# Loop over categorical variables\nfor i, var in enumerate(categorical_variables, 1):\n plt.subplot(2, 2, i) # Subplots 2x2\n sns.boxplot(data=train_df, x=var, y='Annual_Premium', palette='viridis')\n plt.title(f'Annual Award for {var}')\n plt.xlabel(var)\n plt.ylabel('Annual Award')\n plt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:52:28.17864Z","iopub.execute_input":"2024-07-21T05:52:28.178997Z","iopub.status.idle":"2024-07-21T05:53:06.628728Z","shell.execute_reply.started":"2024-07-21T05:52:28.178945Z","shell.execute_reply":"2024-07-21T05:53:06.627855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3.2 - Insurance indicators","metadata":{}},{"cell_type":"code","source":"# Group by vehicle age and gender, adding annual premiums\ngrouped_data = train_df.groupby(['Vehicle_Age', 'Gender'])['Annual_Premium'].sum().reset_index()\n\n# Grouped bar chart\nplt.figure(figsize=(12, 6))\nsns.barplot(data=grouped_data, x='Vehicle_Age', y='Annual_Premium', hue='Gender', palette='viridis')\nplt.title('Total Annual Premium by Vehicle Age and Sex')\nplt.xlabel('Vehicle Age')\nplt.ylabel('Annual Premium Total')\nplt.legend(title='Genre')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:06.630128Z","iopub.execute_input":"2024-07-21T05:53:06.630575Z","iopub.status.idle":"2024-07-21T05:53:09.447277Z","shell.execute_reply.started":"2024-07-21T05:53:06.63054Z","shell.execute_reply":"2024-07-21T05:53:09.446107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of genres\ngenders = train_df['Gender'].unique()\n\n# Figure size\nplt.figure(figsize=(15, 8))\n\n# Loop over genres\nfor i, gender in enumerate(genders, 1):\n plt.subplot(1, 2, i)\n gender_data = train_df[train_df['Gender'] == gender]\n gender_grouped = gender_data.groupby('Vehicle_Age')['Annual_Premium'].sum().reset_index()\n sns.barplot(data=gender_grouped, x='Vehicle_Age', y='Annual_Premium', palette='viridis')\n plt.title(f'Total Annual Premium by Vehicle Age ({gender})')\n plt.xlabel('Vehicle Age')\n plt.ylabel('Annual Premium Total')\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:09.448459Z","iopub.execute_input":"2024-07-21T05:53:09.448751Z","iopub.status.idle":"2024-07-21T05:53:16.911723Z","shell.execute_reply.started":"2024-07-21T05:53:09.448722Z","shell.execute_reply":"2024-07-21T05:53:16.910828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group by vehicle age and insurance status, adding annual premiums\ngrouped_data = train_df.groupby(['Vehicle_Age', 'Previously_Insured'])['Annual_Premium'].sum().reset_index()\n\n# Convert the 'Previously_Insured' column to string for better visualization\ngrouped_data['Previously_Insured'] = grouped_data['Previously_Insured'].astype(str)\n\n# Grouped bar chart\nplt.figure(figsize=(12, 6))\nsns.barplot(data=grouped_data, x='Vehicle_Age', y='Annual_Premium', hue='Previously_Insured', palette='viridis')\nplt.title('Total Annual Premium by Vehicle Age and Insurance Status')\nplt.xlabel('Vehicle Age')\nplt.ylabel('Annual Premium Total')\nplt.legend(title='Previously Insured')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:16.913158Z","iopub.execute_input":"2024-07-21T05:53:16.913533Z","iopub.status.idle":"2024-07-21T05:53:18.736199Z","shell.execute_reply.started":"2024-07-21T05:53:16.913499Z","shell.execute_reply":"2024-07-21T05:53:18.735265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of insurance status\nstatuses = train_df['Previously_Insured'].unique()\n\n# Figure size\nplt.figure(figsize=(15, 8))\n\n# Loop about insurance statuses\nfor i, status in enumerate(statuses, 1):\n plt.subplot(1, 2, i)\n status_data = df[df['Previously_Insured'] == status]\n status_grouped = status_data.groupby('Vehicle_Age')['Annual_Premium'].sum().reset_index()\n sns.barplot(data=status_grouped, x='Vehicle_Age', y='Annual_Premium', palette='viridis')\n plt.title(f'Total Annual Premium by Vehicle Age (Previously Insured: {status})')\n plt.xlabel('Vehicle Age')\n plt.ylabel('Annual Premium Total')\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:18.737385Z","iopub.execute_input":"2024-07-21T05:53:18.737677Z","iopub.status.idle":"2024-07-21T05:53:19.488754Z","shell.execute_reply.started":"2024-07-21T05:53:18.737649Z","shell.execute_reply":"2024-07-21T05:53:19.487832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group by age, gender and vehicle age, adding annual premiums\ngrouped_data = train_df.groupby(['Age', 'Gender', 'Vehicle_Age'])['Annual_Premium'].sum().reset_index()\n\n# Convert the 'Gender' column to string for better visualization\ngrouped_data['Gender'] = grouped_data['Gender'].map({'Male': 'Man', 'Female': 'Woman'})\n\n# Configure the size of the figure\nplt.figure(figsize=(30.5, 10))\n\n# Loop to create graphs separated by vehicle age\nvehicle_ages = grouped_data['Vehicle_Age'].unique()\n\nfor i, vehicle_age in enumerate(vehicle_ages, 1):\n    plt.subplot(2, 2, i)\n    subset = grouped_data[grouped_data['Vehicle_Age'] == vehicle_age]\n    sns.barplot(data=subset, x='Age', y='Annual_Premium', hue='Gender', palette='viridis')\n    plt.title(f'Total Annual Premium by Age and Sex (Vehicle Age: {vehicle_age})')\n    plt.xlabel('Age')\n    plt.ylabel('Annual Premium Total')\n    plt.legend(title='Genre')\n    plt.xticks(rotation=50)\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:19.490124Z","iopub.execute_input":"2024-07-21T05:53:19.490487Z","iopub.status.idle":"2024-07-21T05:53:27.44571Z","shell.execute_reply.started":"2024-07-21T05:53:19.490453Z","shell.execute_reply":"2024-07-21T05:53:27.44479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analysis of the Total Annual Premium by Age and Sex\n\nThe provided graphs show the total annual premium by age and sex, segmented into three categories based on the age of the vehicle: less than 1 year, 1-2 years, and more than 2 years.\n\n#### Observations:\n\n1. **Vehicle Age: < 1 Year**\n   - The total annual premium is highest for younger individuals, peaking around ages 22-25 for both men and women.\n   - Women tend to have a higher total annual premium compared to men in the younger age brackets.\n   - As age increases beyond the mid-30s, the total annual premium decreases steadily for both genders.\n\n2. **Vehicle Age: 1-2 Years**\n   - The peak total annual premium occurs around ages 40-45 for both men and women, with men having a slightly higher total annual premium.\n   - A significant increase in total annual premium is observed from the mid-20s to the early 40s.\n   - After age 45, the total annual premium declines gradually for both men and women.\n\n3. **Vehicle Age: > 2 Years**\n   - The total annual premium is higher for younger individuals, peaking around ages 40-45 for men and women.\n   - Men consistently have a higher total annual premium compared to women across most age ranges.\n   - A steady decline in the total annual premium is observed after the peak age range.\n\n### Key Takeaways:\n\n- **Age Influence**: Younger individuals generally contribute more to the total annual premium, with significant peaks observed in the 22-25 age range for new vehicles and the 40-45 age range for older vehicles.\n- **Gender Differences**: Men tend to have a higher total annual premium than women, especially in the 1-2 years and > 2 years vehicle age categories. However, for vehicles less than 1 year old, women have a higher total annual premium in the younger age brackets.\n- **Vehicle Age Impact**: The age of the vehicle influences the distribution of the total annual premium, with newer vehicles (< 1 year) showing a higher premium for younger individuals and older vehicles (> 2 years) peaking at a later age.\n\n### Recommendations:\n\n- **Targeted Marketing**: Insurance companies could consider targeted marketing strategies for different age groups and genders based on the observed trends in annual premiums.\n- **Product Development**: Develop insurance products that cater specifically to the high-premium age groups, such as younger individuals with new vehicles and middle-aged individuals with older vehicles.\n- **Pricing Strategy**: Adjust pricing strategies to reflect the differences in premium contributions across various age and gender segments.\n","metadata":{}},{"cell_type":"markdown","source":"# Part 3.3 - Correlation analysis","metadata":{}},{"cell_type":"code","source":"# Select the specified columns\ncolumns_of_interest = [\"id\", \"Age\", \"Driving_License\", \"Region_Code\", \"Previously_Insured\", \"Annual_Premium\", \"Policy_Sales_Channel\", \"Vintage\", \"Response\"]\ndf_selected = df[columns_of_interest]\n\n# Calculate the correlation matrix\ncorrelation_matrix = df_selected.corr()\n\n# Configure the size of the figure\nplt.figure(figsize=(14, 10))\n\n# Correlation heatmap\nsns.heatmap(correlation_matrix, annot=True, cmap='viridis', fmt='.2f')\nplt.title('Correlation Matrix Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:27.447086Z","iopub.execute_input":"2024-07-21T05:53:27.447453Z","iopub.status.idle":"2024-07-21T05:53:28.214599Z","shell.execute_reply.started":"2024-07-21T05:53:27.447419Z","shell.execute_reply":"2024-07-21T05:53:28.213675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Matrix Interpretation\n\nThe correlation between variables helps to understand the linear relationship between them. The correlation matrix ranges from -1 to 1, where:\n\n- 1 indicates a perfect positive correlation.\n- -1 indicates a perfect negative correlation.\n- 0 indicates no linear correlation.\n\n### Observations:\n\n1. **id**: \n   - No significant correlation with any other variable. This is expected as the id should be a unique identifier without a relationship to other features.\n\n2. **Age**:\n   - Shows a moderate negative correlation with `Previously_Insured` (-0.25).\n   - Shows a moderate negative correlation with `Policy_Sales_Channel` (-0.58).\n   - Shows a weak positive correlation with `Response` (0.11).\n\n3. **Driving_License**:\n   - No significant correlations with other variables.\n\n4. **Region_Code**:\n   - No significant correlations with other variables.\n\n5. **Previously_Insured**:\n   - Shows a weak positive correlation with `Policy_Sales_Channel` (0.22).\n   - Shows a moderate negative correlation with `Response` (-0.34).\n\n6. **Annual_Premium**:\n   - No significant correlations with other variables.\n\n7. **Policy_Sales_Channel**:\n   - Shows a moderate negative correlation with `Age` (-0.58).\n   - Shows a weak positive correlation with `Previously_Insured` (0.22).\n   - Shows a weak negative correlation with `Response` (-0.14).\n\n8. **Vintage**:\n   - No significant correlations with other variables.\n\n9. **Response**:\n   - Shows correlations already mentioned with `Previously_Insured` (-0.34), `Age` (0.11), and `Policy_Sales_Channel` (-0.14).\n\n### Conclusions:\n\n- **Age**: Age has a moderate negative relationship with `Previously_Insured` and `Policy_Sales_Channel`, suggesting that younger customers are less likely to be previously insured and to be sold by certain channels.\n- **Previously_Insured**: Customers who are previously insured are less likely to respond positively (`Response`) to the new insurance offer.\n- **Policy_Sales_Channel**: Certain sales channels have a negative relationship with customer age and a weak correlation with response (`Response`), indicating that some channels may be more effective for different age groups.\n- **Response**: The response to the insurance offer has a moderate negative correlation with `Previously_Insured` and a weak positive correlation with customer age.\n\nThese correlations can be useful for better understanding the data and guiding marketing and sales strategies, as well as for adjustments in the machine learning model.\n","metadata":{}},{"cell_type":"markdown","source":"# Part 3.4 - Boxplot analysis identifying outliers","metadata":{}},{"cell_type":"code","source":"# Select numeric columns\nnumeric_columns = [\"Age\", \"Annual_Premium\", \"Vintage\"]\n\n# Configure the size of the figure\nplt.figure(figsize=(18, 6))\n\n# Loop to create boxplots for each numeric column\nfor i, column in enumerate(numeric_columns, 1):\n    plt.subplot(1, 3, i)\n    sns.boxplot(data=train_df, y=column, palette='viridis')\n    plt.title(f'Boxplot of {column}')\n    plt.ylabel(column)\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:28.21578Z","iopub.execute_input":"2024-07-21T05:53:28.216113Z","iopub.status.idle":"2024-07-21T05:53:34.197159Z","shell.execute_reply.started":"2024-07-21T05:53:28.216076Z","shell.execute_reply":"2024-07-21T05:53:34.196209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select numeric columns\nnumeric_columns = [\"Age\", \"Annual_Premium\", \"Vintage\"]\n\n# Configure the size of the figure\nplt.figure(figsize=(18, 6))\n\n# Loop to create fiddle plots for each numeric column, separated by Response\nfor i, column in enumerate(numeric_columns, 1):\n    plt.subplot(1, 3, i)\n    sns.boxplot(data=train_df, x='Response', y=column, palette='viridis')\n    plt.title(f'Violin Chart of {column} by Response')\n    plt.xlabel('Response')\n    plt.ylabel(column)\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()\n\n# Descriptive statistics separated by Response\nfor column in numeric_columns:\n    print(f'\\nDescriptive Statistics of {column} by Response:')\n    print(train_df.groupby('Response')[column].describe())","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:34.198237Z","iopub.execute_input":"2024-07-21T05:53:34.198536Z","iopub.status.idle":"2024-07-21T05:53:44.744667Z","shell.execute_reply.started":"2024-07-21T05:53:34.19851Z","shell.execute_reply":"2024-07-21T05:53:44.743561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select numeric columns\nnumeric_columns = [\"Age\", \"Annual_Premium\", \"Vintage\"]\n\n# Function to remove outliers using IQR\ndef remove_outliers(train_df, columns):\n    for columns in columns:\n        Q1 = df[column].quantile(0.25)\n        Q3 = df[column].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        train_df = train_df[(train_df[column] >= lower_bound) & (train_df[column] <= upper_bound)]\n        return train_df\n\n# Remove outliers from the DataFrame\ndf_cleaned = remove_outliers(train_df, numeric_columns)\n\n# Check the DataFrame dimension after removing outliers\nprint(f\"Original dimension: {train_df.shape}\")\nprint(f\"Dimension after removing outliers: {df_cleaned.shape}\")\n\n# View the first records of the cleaned DataFrame\ndf_cleaned.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:44.746218Z","iopub.execute_input":"2024-07-21T05:53:44.746595Z","iopub.status.idle":"2024-07-21T05:53:45.411854Z","shell.execute_reply.started":"2024-07-21T05:53:44.746559Z","shell.execute_reply":"2024-07-21T05:53:45.41092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select numeric columns\nnumeric_columns = [\"Age\", \"Annual_Premium\", \"Vintage\"]\n\n# Configure the size of the figure\nplt.figure(figsize=(18, 6))\n\n# Loop to create fiddle plots for each numeric column, separated by Response\nfor i, column in enumerate(numeric_columns, 1):\n    plt.subplot(1, 3, i)\n    sns.boxplot(data=df_cleaned, x='Response', y=column, hue=\"Response\", palette='viridis')\n    plt.title(f'Violin Chart of {column} by Response')\n    plt.xlabel('Response')\n    plt.ylabel(column)\n\nplt.tight_layout()\nplt.grid(False)\nplt.show()\n\n# Descriptive statistics separated by Response\nfor column in numeric_columns:\n    print(f'\\nDescriptive Statistics of {column} by Response:')\n    print(df_cleaned.groupby('Response')[column].describe())","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:53:45.413072Z","iopub.execute_input":"2024-07-21T05:53:45.413363Z","iopub.status.idle":"2024-07-21T05:54:04.981783Z","shell.execute_reply.started":"2024-07-21T05:53:45.413336Z","shell.execute_reply":"2024-07-21T05:54:04.980739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 4 - Pré-processamento","metadata":{}},{"cell_type":"code","source":"def optimize_memory_usage(df_cleaned):\n    \"\"\"\n    Optimizes the memory usage of a pandas DataFrame by converting categorical columns\n    and adjusting the precision of numerical columns.\n    \n    Parameters:\n    df_cleaned (pd.DataFrame): DataFrame to be optimized.\n    \n    Returns:\n    pd.DataFrame: Optimized DataFrame.\n    \"\"\"\n    # View memory usage before optimization\n    print(\"Memory usage before optimization:\")\n    print(df_cleaned.memory_usage(deep=True))\n    print()\n    \n    # Converting categorical columns to dtype 'category'\n    categorical_columns = ['Gender', 'Driving_License', 'Region_Code', 'Previously_Insured', \n                           'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel', \n                           'Response', 'Age_Bucket']\n    \n    for col in categorical_columns:\n        if col in df_cleaned.columns:\n            df_cleaned[col] = df_cleaned[col].astype('category')\n    \n    # Reducing precision of integers\n    # Assuming age is within 0 to 127\n    if 'Age' in df_cleaned.columns:\n        df_cleaned['Age'] = df_cleaned['Age'].astype('int8')\n    \n    # Adjust according to maximum value for Annual_Premium\n    if 'Annual_Premium' in df_cleaned.columns:\n        df_cleaned['Annual_Premium'] = df_cleaned['Annual_Premium'].astype('int32')\n    \n    # Assuming the value is within the range of int16 for Vintage\n    if 'Vintage' in df_cleaned.columns:\n        df_cleaned['Vintage'] = df_cleaned['Vintage'].astype('int16')\n    \n    # View memory usage after applying conversions\n    print(\"Memory usage after applying conversions:\")\n    print(df_cleaned.memory_usage(deep=True))\n    \n    # Check detailed memory usage\n    print(df_cleaned.info(memory_usage='deep'))\n    print()\n    return df_cleaned\n\n# Optimizing the DataFrames\ndf_cleaned_optimized_train = optimize_memory_usage(df_cleaned)\ntest_df_optimized_test = optimize_memory_usage(test_df)\ndf_optimized = optimize_memory_usage(df)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:04.990393Z","iopub.execute_input":"2024-07-21T05:54:04.990725Z","iopub.status.idle":"2024-07-21T05:54:26.393649Z","shell.execute_reply.started":"2024-07-21T05:54:04.990695Z","shell.execute_reply":"2024-07-21T05:54:26.392678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Copy dataset\ntrain_df = df_cleaned_optimized_train.copy()\ntest_df = df_optimized.copy()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:26.395157Z","iopub.execute_input":"2024-07-21T05:54:26.395818Z","iopub.status.idle":"2024-07-21T05:54:26.510899Z","shell.execute_reply.started":"2024-07-21T05:54:26.395779Z","shell.execute_reply":"2024-07-21T05:54:26.510112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 5 - Data cleaning","metadata":{}},{"cell_type":"code","source":"# 1. Handling Missing Values\nprint(\"Number of missing values ​​per column:\")\nprint(df_optimized.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:26.512008Z","iopub.execute_input":"2024-07-21T05:54:26.512292Z","iopub.status.idle":"2024-07-21T05:54:26.524443Z","shell.execute_reply.started":"2024-07-21T05:54:26.512264Z","shell.execute_reply":"2024-07-21T05:54:26.523535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View missing values\nplt.figure(figsize=(10, 6))\nsns.heatmap(df_optimized.isnull(), cbar=False, cmap=\"viridis\")\nplt.title(\"Viewing Missing Values in the Training Set\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:26.525543Z","iopub.execute_input":"2024-07-21T05:54:26.525797Z","iopub.status.idle":"2024-07-21T05:54:30.720943Z","shell.execute_reply.started":"2024-07-21T05:54:26.525773Z","shell.execute_reply":"2024-07-21T05:54:30.720019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 6 - Feature engineering","metadata":{}},{"cell_type":"code","source":"# Importing library\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical variables\nlabel_encoder = LabelEncoder()\ndf_optimized['Gender'] = label_encoder.fit_transform(df_optimized['Gender'])\ndf_optimized['Vehicle_Age'] = label_encoder.fit_transform(df_optimized['Vehicle_Age'])\ndf_optimized['Vehicle_Damage'] = label_encoder.fit_transform(df_optimized['Vehicle_Damage'])\n\n# Viewing\nlabel_encoder","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:30.731123Z","iopub.execute_input":"2024-07-21T05:54:30.73154Z","iopub.status.idle":"2024-07-21T05:54:31.047577Z","shell.execute_reply.started":"2024-07-21T05:54:30.731508Z","shell.execute_reply":"2024-07-21T05:54:31.046694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the first DataFrame records after encoding\ndf_optimized","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.048836Z","iopub.execute_input":"2024-07-21T05:54:31.049139Z","iopub.status.idle":"2024-07-21T05:54:31.069791Z","shell.execute_reply.started":"2024-07-21T05:54:31.049113Z","shell.execute_reply":"2024-07-21T05:54:31.068876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Analysis\n\nWe applied the Label Encoder to the categorical variables, transforming them into numerical values. This transformation resulted in the creation of a new feature called **Gender**, **Vehicle_Age**, **Vehicle_Damage**, **Age_Bucket** The encoding process is essential because many machine learning algorithms require input variables to be numerical to function correctly.\n\nThe **Gender**, **Vehicle_Age**, **Vehicle_Damage**, **Age_Bucket**  variable will be used as an alternative to the original Transported variable. By transforming categorical variables into numerical ones, we ensure that the model can interpret and process this data effectively. This is particularly important for non-ordinal categorical variables, where each category is converted into a distinct number without implying an order.\n\nAdditionally, the new **Gender**, **Vehicle_Age**, **Vehicle_Damage**, **Age_Bucket** feature will allow us to evaluate whether this transformation positively influences the performance of the predictive models. By comparing the results obtained using the original variable and the transformed variable, we can determine which approach offers better predictions. This process is part of a broader feature engineering strategy aimed at optimizing input data to improve the accuracy and robustness of machine learning models.","metadata":{}},{"cell_type":"code","source":"# Fill missing values\ndf_optimized.fillna(method='ffill', inplace=True)\ndf_optimized.fillna(method='ffill', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.070878Z","iopub.execute_input":"2024-07-21T05:54:31.07118Z","iopub.status.idle":"2024-07-21T05:54:31.082022Z","shell.execute_reply.started":"2024-07-21T05:54:31.071154Z","shell.execute_reply":"2024-07-21T05:54:31.081027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 7 - Training and testing division","metadata":{}},{"cell_type":"code","source":"# Select features\n#features = ['Gender', 'Age', 'Driving_License', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n\n# Deivisão\n#X = df_test_df_optimized[features]\n#y = df_test_df_optimized['Response']\n\n# Resources\nX = df_optimized.drop(columns=['Response'])  \n\n# Target variable\ny = df_optimized['Response']  ","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.083343Z","iopub.execute_input":"2024-07-21T05:54:31.083702Z","iopub.status.idle":"2024-07-21T05:54:31.102124Z","shell.execute_reply.started":"2024-07-21T05:54:31.083649Z","shell.execute_reply":"2024-07-21T05:54:31.101295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing rows and columns x\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.103246Z","iopub.execute_input":"2024-07-21T05:54:31.103566Z","iopub.status.idle":"2024-07-21T05:54:31.110331Z","shell.execute_reply.started":"2024-07-21T05:54:31.103537Z","shell.execute_reply":"2024-07-21T05:54:31.108983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing rows and columns\ny.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.111551Z","iopub.execute_input":"2024-07-21T05:54:31.111856Z","iopub.status.idle":"2024-07-21T05:54:31.118252Z","shell.execute_reply.started":"2024-07-21T05:54:31.111828Z","shell.execute_reply":"2024-07-21T05:54:31.117176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we performed the division of the variables into features and the target variable. First, we separated the independent variables, which are the features used for predictive modeling. These features are the input data that the model will use to learn patterns and make predictions. Next, we isolated the dependent variable, or the target variable, which is the value we aim to predict. This process is crucial for building and training the model, ensuring that the features are correctly identified and that the model can learn the relationship between these features and the target variable. By properly dividing the data, we enhance the model's ability to accurately predict outcomes based on the given inputs","metadata":{}},{"cell_type":"markdown","source":"# Part 8 - Model training","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nfrom sklearn.model_selection import train_test_split\n\n# Training and testing division\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Viewing training data\nprint(\"Viewing rows and columns given by X train\", X_train.shape)\n\n# Viewing test data\nprint(\"Viewing rows and columns given y train\", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.119318Z","iopub.execute_input":"2024-07-21T05:54:31.119597Z","iopub.status.idle":"2024-07-21T05:54:31.194201Z","shell.execute_reply.started":"2024-07-21T05:54:31.119573Z","shell.execute_reply":"2024-07-21T05:54:31.19317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we conducted the training of the model using a train-test split. We adopted an 80/20 division, where 80% of the data was used for training and the remaining 20% was reserved for testing. This procedure is crucial for accurately evaluating the model's performance. The training set allows the model to learn patterns and relationships within the data, while the test set, which the model has not seen during training, is used to validate its ability to generalize and predict new data. Additionally, this approach helps identify and mitigate issues such as overfitting, ensuring that the model not only memorizes the training data but also performs well on unseen data.","metadata":{}},{"cell_type":"code","source":"# Converting categorical columns to dummy variables\nX_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(X_test)\n\n# Viewing training data\nprint(\"Viewing rows and columns given by X train\", X_train.shape)\n\n# Viewing test data\nprint(\"Viewing rows and columns given y train\", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.195259Z","iopub.execute_input":"2024-07-21T05:54:31.19559Z","iopub.status.idle":"2024-07-21T05:54:31.293731Z","shell.execute_reply.started":"2024-07-21T05:54:31.19556Z","shell.execute_reply":"2024-07-21T05:54:31.292836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1) Section - Machine learning","metadata":{}},{"cell_type":"markdown","source":"# Part 9 - Machine learning model","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Importing machine learning model library\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# Importing library for metrics machine learning models\nfrom sklearn.metrics import accuracy_score\n\n# Models to be evaluated\nmodels = [GaussianNB(), # Naive Bayes Model\n          DecisionTreeClassifier(random_state=42), # Decision Tree Model\n          RandomForestClassifier(n_estimators=100, random_state=42), # Random forest model\n          LogisticRegression(random_state=50), # Logistic regression model\n          AdaBoostClassifier(random_state=45), # Ada Boost Model\n          XGBClassifier(), # XGBoost Model Parameter tree_method='gpu_hist' for XGBoost GPU\n          LGBMClassifier()] # LightGBM Model Parameter device='gpu' for LightGBM GPU\n\n# Evaluate each model\nfor i, model in enumerate(models):\n    model.fit(X_train, y_train)\n    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n    print(model)\n    print()\n    print(f\"Model {i+1}: {type(model).__name__}\")\n    print()\n    print(f\"Training Accuracy: {train_accuracy}\")\n    print(f\"Testing Accuracy: {test_accuracy}\")\n    print(\"------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:54:31.295015Z","iopub.execute_input":"2024-07-21T05:54:31.295714Z","iopub.status.idle":"2024-07-21T05:58:19.856689Z","shell.execute_reply.started":"2024-07-21T05:54:31.295674Z","shell.execute_reply":"2024-07-21T05:58:19.855573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 6: Evaluate the model\ntrain_accuracy = accuracy_score(y_train, model.predict(X_train))\ntest_accuracy = accuracy_score(y_test, model.predict(X_test))\nprint(f\"Training Accuracy: {train_accuracy}\")\nprint()\nprint(f\"Testing Accuracy: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:58:19.85799Z","iopub.execute_input":"2024-07-21T05:58:19.858568Z","iopub.status.idle":"2024-07-21T05:58:21.323625Z","shell.execute_reply.started":"2024-07-21T05:58:19.858541Z","shell.execute_reply":"2024-07-21T05:58:21.32266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 7: Make predictions on the test set\n#test_features = test_df[features]\npredictions = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:58:21.324891Z","iopub.execute_input":"2024-07-21T05:58:21.325629Z","iopub.status.idle":"2024-07-21T05:58:21.606575Z","shell.execute_reply.started":"2024-07-21T05:58:21.325592Z","shell.execute_reply":"2024-07-21T05:58:21.60574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 10 - Feature importances","metadata":{}},{"cell_type":"markdown","source":"- \"Feature importances\" (importância das características) refers to the measure of how important each feature is for a machine learning model in making predictions or classifications. In other words, it is a way to quantify the impact or contribution of each feature to the decisions made by the model.\n\n- In many machine learning algorithms such as decision trees, Random Forest, Gradient Boosting, among others, it is possible to calculate the importance of features during model training. This is done by observing how each feature influences the decisions made by the model when dividing the data into decision tree nodes or by weighing the features in other model structures.\n\n- Analyzing feature importances is valuable because it can provide insights into which features are most relevant to the problem at hand. This information can be used to optimize the model, remove irrelevant or redundant features, identify important factors for prediction, and even assist in interpreting the model's results.","metadata":{}},{"cell_type":"code","source":"# Train models that support feature importances\n\n# Set Seaborn style\nsns.set_palette(\"Set2\")\n\nmodels_with_feature_importances = [(\"DecisionTreeClassifier\", DecisionTreeClassifier(random_state=42)),\n                                   (\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100, random_state=42)),\n                                   (\"XGBClassifier\", XGBClassifier(random_state=42)),\n                                   (\"LGBMClassifier\", LGBMClassifier(random_state=42))]\n\n# Iterate over models\nfor model_name, model in models_with_feature_importances:\n    \n    # Train model\n    model.fit(X_train, y_train)\n    \n    # Get importance of features\n    if hasattr(model, 'feature_importances_'):\n        feature_importances = model.feature_importances_\n    else:\n        # If the model does not have feature_importances_, continue to the next model\n        print(f\"{model_name} does not support feature importances.\")\n        continue\n\n    # Create DataFrame for easier viewing\n    feature_importances_df = pd.DataFrame({'Feature': X_train.columns, \n                                           'Importance': feature_importances})\n    \n    # Sort by importance\n    feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n    \n    # Plot\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=feature_importances_df[:10])\n    plt.title(f\"Top 10 Features - {model_name}\")\n    plt.xlabel('Importance')\n    plt.ylabel('Feature')\n    plt.grid(False)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T05:58:21.607739Z","iopub.execute_input":"2024-07-21T05:58:21.608061Z","iopub.status.idle":"2024-07-21T06:00:43.679359Z","shell.execute_reply.started":"2024-07-21T05:58:21.608033Z","shell.execute_reply":"2024-07-21T06:00:43.678355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance Interpretation\n\nThe graph shows the top 10 most important features used by the `LGBMClassifier` model for predicting the target variable. Each feature's importance is measured by the contribution it makes to the model's predictions.\n\n1. **Age**: This is the most important feature, contributing the most to the model's decisions.\n2. **id**: This feature also plays a significant role, indicating it has a strong impact on predictions.\n3. **Vintage**: The age of the policy has a considerable impact on the model.\n4. **Annual_Premium**: The annual premium amount is another crucial feature influencing the model.\n5. **Vehicle_Damage**: Indicates if the vehicle was damaged, which is important for the model.\n6. **Vehicle_Age**: The age of the vehicle is an important factor in the predictions.\n7. **Previously_Insured_0**: Indicates whether the customer was previously insured, which affects the model's output.\n8. **Policy_Sales_Channel_160.0**: This sales channel feature is relevant for the model's decisions.\n9. **Policy_Sales_Channel_156.0**: Another sales channel that impacts the model's performance.\n10. **Policy_Sales_Channel_152.0**: Also, a significant feature among the top 10, affecting the model's predictions.\n\n### Key Takeaways\n\n- **Age** is the most influential feature, suggesting that the customer's age is crucial in determining the target outcome.\n- **id** being highly important could indicate some underlying pattern or information encoded within this feature.\n- **Vintage**, **Annual_Premium**, and **Vehicle_Damage** are also highly relevant, indicating that the duration of the policy, the premium amount, and the vehicle's damage status significantly impact the predictions.\n- The presence of multiple **Policy_Sales_Channel** features in the top 10 highlights the importance of the sales channel through which the policy was sold in influencing the model's predictions.\n\n### Recommendations\n\n- **Further Analysis**: Investigate why certain features like **id** are highly important to understand if they are capturing specific patterns or if they need further preprocessing.\n- **Feature Engineering**: Consider creating new features based on the most important ones to potentially improve the model's performance.\n- **Model Tuning**: Use the insights from feature importance to fine-tune the model, focusing on the most influential features.\n","metadata":{}},{"cell_type":"markdown","source":"# Part 11 - Métricas resultado","metadata":{}},{"cell_type":"code","source":"# plot confusion matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Evaluate each model\nfor i, model in enumerate(models):\n    model.fit(X_train, y_train)\n    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n    \n    print(f\"Model {i+1}: {type(model).__name__}\")\n    print(f\"Training Accuracy: {train_accuracy}\")\n    print(f\"Testing Accuracy: {test_accuracy}\")\n\n    # Calculate and plot the confusion matrix\n    cm = confusion_matrix(y_test, model.predict(X_test))\n    plt.figure()\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n                xticklabels=[\"Not Transported\", \"Transported\"], \n                yticklabels=[\"Not Transported\", \"Transported\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(f\"Confusion Matrix - Model {i+1}: {type(model).__name__}\")\n    plt.show()\n    print(\"------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:00:43.680744Z","iopub.execute_input":"2024-07-21T06:00:43.681113Z","iopub.status.idle":"2024-07-21T06:04:41.12133Z","shell.execute_reply.started":"2024-07-21T06:00:43.68107Z","shell.execute_reply":"2024-07-21T06:04:41.120317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix Details\n\nThe matrix represents the performance of the `LGBMClassifier` model on the test dataset. Here's the breakdown of the confusion matrix:\n\n- **True Negatives (TN)**: 66,646\n  - These are the instances where the actual class was \"Not Transported\" and the model also predicted \"Not Transported\".\n  \n- **False Positives (FP)**: 53\n  - These are the instances where the actual class was \"Not Transported\" but the model predicted \"Transported\".\n  \n- **False Negatives (FN)**: 9,505\n  - These are the instances where the actual class was \"Transported\" but the model predicted \"Not Transported\".\n  \n- **True Positives (TP)**: 18\n  - These are the instances where the actual class was \"Transported\" and the model also predicted \"Transported\".\n  \n### Metrics Calculation\n\nBased on these values, we can calculate various performance metrics:\n\n1. **Accuracy**:\n   $$\n   \\text{Accuracy} = \\frac{\\text{TN} + \\text{TP}}{\\text{TN} + \\text{FP} + \\text{FN} + \\text{TP}} = \\frac{66,646 + 18}{66,646 + 53 + 9,505 + 18} = \\frac{66,664}{76,222} \\approx 0.874\n   $$\n\n2. **Precision** (for the positive class \"Transported\"):\n   $$\n   \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} = \\frac{18}{18 + 53} \\approx 0.253\n   $$\n\n3. **Recall** (Sensitivity, for the positive class \"Transported\"):\n   $$\n   \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{18}{18 + 9,505} \\approx 0.002\n   $$\n\n4. **F1 Score** (for the positive class \"Transported\"):\n   $$\n   \\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\cdot \\frac{0.253 \\cdot 0.002}{0.253 + 0.002} \\approx 0.004\n   $$\n\n5. **Specificity** (for the negative class \"Not Transported\"):\n   $$\n   \\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} = \\frac{66,646}{66,646 + 53} \\approx 0.999\n   $$\n\n### Interpretation\n\n- The accuracy of the model is relatively high at approximately 87.4%. However, accuracy can be misleading in imbalanced datasets.\n- The precision for the \"Transported\" class is quite low, indicating that when the model predicts \"Transported,\" it is correct about 25.3% of the time.\n- The recall for the \"Transported\" class is extremely low, indicating that the model is missing a large number of \"Transported\" cases.\n- The F1 score, which considers both precision and recall, is also very low, suggesting poor performance for the \"Transported\" class.\n- The specificity is very high, meaning the model is very good at identifying \"Not Transported\" cases correctly.\n\n### Conclusion\n\nThe model has a high ability to correctly identify \"Not Transported\" cases but struggles significantly with correctly identifying \"Transported\" cases. This indicates a potential issue with class imbalance or model bias towards the majority class (\"Not Transported\"). Further steps could include rebalancing the dataset, using different metrics for model evaluation, or trying other algorithms better suited for imbalanced datasets.\n","metadata":{}},{"cell_type":"code","source":"# ROC curve models\n\n# Importing library\nfrom sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n\n# Models to be evaluated\nmodels = [GaussianNB(),\n          DecisionTreeClassifier(random_state=42),\n          RandomForestClassifier(n_estimators=100, random_state=42),\n          LogisticRegression(random_state=42),\n          AdaBoostClassifier(random_state=42),\n          XGBClassifier(random_state=42),\n          LGBMClassifier()]\n\n# Evaluate each model\nfor i, model in enumerate(models):\n    model.fit(X_train, y_train)\n    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n    print(f\"Model {i+1}: {type(model).__name__}\")\n    print(f\"Training Accuracy: {train_accuracy}\")\n    print(f\"Testing Accuracy: {test_accuracy}\")\n\n    # Calculate positive class probabilities\n    y_probs = model.predict_proba(X_test)[:, 1]\n    \n    # Calculate the ROC curve\n    fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n    \n    # Calculate the area under the ROC curve (AUC)\n    auc = roc_auc_score(y_test, y_probs)\n    \n    # Plot the ROC curve\n    plt.figure()\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.2f}')\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'ROC Curve - Model {i+1}: {type(model).__name__}')\n    plt.legend(loc=\"lower right\")\n    plt.grid(False)\n    plt.show()\n    \n    print(\"------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:04:41.123064Z","iopub.execute_input":"2024-07-21T06:04:41.123752Z","iopub.status.idle":"2024-07-21T06:08:36.987128Z","shell.execute_reply.started":"2024-07-21T06:04:41.123714Z","shell.execute_reply":"2024-07-21T06:08:36.986195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC Curve Explanation\n\nThe provided ROC (Receiver Operating Characteristic) curve is a graphical representation of the performance of the `LGBMClassifier` model. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n\n#### Key Components of the ROC Curve:\n\n1. **True Positive Rate (TPR)**:\n   - Also known as sensitivity or recall.\n   - Represents the proportion of actual positives correctly identified by the model.\n   - Formula: $ \\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n\n2. **False Positive Rate (FPR)**:\n   - Represents the proportion of actual negatives incorrectly identified as positives by the model.\n   - Formula: $ \\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} $\n\n3. **Diagonal Line (Baseline)**:\n   - The diagonal line (dashed) represents the performance of a random classifier.\n   - Any point along this line indicates that the classifier is performing no better than random guessing.\n\n4. **ROC Curve**:\n   - The blue curve represents the performance of the `LGBMClassifier` model across different threshold values.\n   - The closer the curve follows the left-hand border and then the top border of the ROC space, the better the model's performance.\n\n5. **AUC (Area Under the Curve)**:\n   - The area under the ROC curve (AUC) is a single scalar value that summarizes the performance of the model.\n   - AUC ranges from 0 to 1, with a higher value indicating better model performance.\n   - An AUC of 0.86 means that there is an 86% chance that the model will distinguish between a randomly chosen positive instance and a randomly chosen negative instance.\n\n### Interpretation of the ROC Curve for `LGBMClassifier`:\n\n- **Model Performance**:\n  - The ROC curve for the `LGBMClassifier` (blue curve) shows that the model performs well, as it stays above the diagonal baseline and close to the top left corner of the plot.\n  - The AUC score of 0.86 indicates that the model has a good ability to discriminate between the positive and negative classes.\n\n- **Threshold Selection**:\n  - The ROC curve helps in selecting the optimal threshold for classification. Depending on the business requirement, you might want to maximize TPR (sensitivity) while keeping FPR low.\n\n### Summary:\n\n- **High AUC Score**: The model has a strong discriminative power with an AUC of 0.86.\n- **Effective Classifier**: The curve's proximity to the top left corner indicates that the `LGBMClassifier` is effective at distinguishing between positive and negative instances.\n- **Threshold Decision**: The ROC curve provides insights into the trade-offs between TPR and FPR for different thresholds, aiding in the selection of the most appropriate threshold based on the specific use case.\n","metadata":{}},{"cell_type":"code","source":"# Classification report\n# Importing library - Classification report models\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Models to be evaluated\nmodels = [GaussianNB(),\n          DecisionTreeClassifier(random_state=42),\n          RandomForestClassifier(n_estimators=100, random_state=42),\n          LogisticRegression(random_state=42),\n          AdaBoostClassifier(random_state=42),\n          XGBClassifier(random_state=42),\n          LGBMClassifier()]\n\n# Evaluate each model\nfor i, model in enumerate(models):\n    model.fit(X_train, y_train)\n    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n    print()\n    \n    print(f\"Model {i+1}: {type(model).__name__}\")\n    print()\n    print(f\"Training Accuracy: {train_accuracy}\")\n    print(f\"Testing Accuracy: {test_accuracy}\")\n\n    # Gerar relatório de classificação\n    report = classification_report(y_test, model.predict(X_test))\n    print()\n    print(\"Classification Report:\")\n    print()\n    print(report)\n    print()\n    \n    print(\"=======================================\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:08:36.988672Z","iopub.execute_input":"2024-07-21T06:08:36.989069Z","iopub.status.idle":"2024-07-21T06:12:32.092279Z","shell.execute_reply.started":"2024-07-21T06:08:36.989032Z","shell.execute_reply":"2024-07-21T06:12:32.091162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report Analysis\n\nThe provided classification report gives a detailed breakdown of the performance metrics for the `LGBMClassifier` model on both the training and testing datasets. Here is a detailed interpretation of the results:\n\n#### Model Performance Metrics:\n\n1. **Training Accuracy**: 0.8781614171807915\n   - This indicates that the model correctly predicted approximately 87.8% of the instances in the training dataset.\n\n2. **Testing Accuracy**: 0.87460831329537404\n   - This shows that the model correctly predicted approximately 87.4% of the instances in the testing dataset, indicating a slight drop from the training accuracy which suggests minimal overfitting.\n\n#### Detailed Classification Report:\n\nThe classification report breaks down the performance of the model for each class:\n\n1. **Class 0 (Not Transported)**:\n   \n   - **Precision**: 0.88\n     \n     - This means that 88% of the instances predicted as \"Not Transported\" were correctly classified.\n   \n   - **Recall**: 1.00\n     \n     - This indicates that the model identified all actual \"Not Transported\" instances correctly.\n   \n   - **F1-Score**: 0.93\n     \n     - The F1-score is the harmonic mean of precision and recall, given by the formula:\n       \n       $$\n       F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n       $$\n       \n     - For this class, the F1-score is 0.93.\n   \n   - **Support**: 66,699\n     \n     - The number of actual instances of \"Not Transported\" in the dataset.\n\n2. **Class 1 (Transported)**:\n   \n   - **Precision**: 0.25\n     \n     - This indicates that only 25% of the instances predicted as \"Transported\" were correctly classified.\n   \n   - **Recall**: 0.00\n     \n     - This means the model failed to identify any actual \"Transported\" instances correctly.\n   \n   - **F1-Score**: 0.00\n     \n     - The F1-score is 0 because both precision and recall are very low.\n   \n   - **Support**: 9,523\n     \n     - The number of actual instances of \"Transported\" in the dataset.\n\n#### Overall Metrics:\n\n- **Accuracy**: 0.87\n  - The overall accuracy of the model, given by the formula:\n    $$\n    \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n    $$\n  - This is consistent with the testing accuracy, showing that 87% of all instances were correctly classified.\n\n- **Macro Average**:\n  - **Precision**: 0.56\n    - The unweighted average of precision for all classes.\n  - **Recall**: 0.50\n    - The unweighted average of recall for all classes.\n  - **F1-Score**: 0.47\n    - The unweighted average of F1-scores for all classes, showing a moderate overall performance.\n\n- **Weighted Average**:\n  - **Precision**: 0.80\n    - The average precision weighted by the number of instances in each class.\n  - **Recall**: 0.87\n    - The average recall weighted by the number of instances in each class.\n  - **F1-Score**: 0.82\n    - The average F1-score weighted by the number of instances in each class, indicating good overall performance despite the poor performance on the minority class.\n\n### Summary:\n\n- The model performs well in predicting the majority class (Not Transported) but struggles significantly with the minority class (Transported).\n- The high recall and precision for the majority class indicate that the model is highly confident and accurate in identifying instances of the majority class.\n- The poor performance on the minority class suggests that the model may be biased towards the majority class, likely due to class imbalance.\n- The overall accuracy and weighted averages are high, but the macro averages reveal the poor performance on the minority class, highlighting the need for addressing class imbalance.\n\n### Recommendations:\n\n- **Class Imbalance Handling**: Consider techniques such as oversampling the minority class, undersampling the majority class, or using different evaluation metrics that account for class imbalance.\n- **Model Tuning**: Experiment with different models, hyperparameters, or threshold adjustments to improve the recall and precision for the minority class.\n- **Feature Engineering**: Investigate additional features or different feature transformations that might help the model better distinguish between the classes.\n","metadata":{}},{"cell_type":"markdown","source":"# Part 12 - Machine learning model - Parameters with GPU","metadata":{}},{"cell_type":"markdown","source":"- Here we applied a machine learning model using the LightGBM algorithm, optimized with parameters specifically for GPU.\nThis model employs advanced machine learning techniques and is specially designed to handle large datasets efficiently and swiftly. Additionally, we implemented a series of preprocessing and feature engineering techniques to ensure the best possible model performance. The training process involved cross-validation steps and fine-tuning of hyperparameters, aiming to further enhance the model's accuracy and generalization. In the end, we achieved promising results, demonstrating the effectiveness and potential of this approach in solving complex data analysis problems.","metadata":{}},{"cell_type":"code","source":"# New dataset to avoid problems with the previous dataset here we will use the XGBoost, LightLBM models\n\n# Viewing train_df dataset\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:32.093864Z","iopub.execute_input":"2024-07-21T06:12:32.094262Z","iopub.status.idle":"2024-07-21T06:12:32.11293Z","shell.execute_reply.started":"2024-07-21T06:12:32.094226Z","shell.execute_reply":"2024-07-21T06:12:32.112003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing train_df dataset\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:32.114221Z","iopub.execute_input":"2024-07-21T06:12:32.114486Z","iopub.status.idle":"2024-07-21T06:12:32.134907Z","shell.execute_reply.started":"2024-07-21T06:12:32.114463Z","shell.execute_reply":"2024-07-21T06:12:32.133871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing test_df dataset\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:32.136375Z","iopub.execute_input":"2024-07-21T06:12:32.137125Z","iopub.status.idle":"2024-07-21T06:12:32.156171Z","shell.execute_reply.started":"2024-07-21T06:12:32.137064Z","shell.execute_reply":"2024-07-21T06:12:32.155236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing label encoder library\nfrom sklearn.preprocessing import LabelEncoder\n\n# # Copy the original data to avoid modifying the original DataFrame\ntrain_df = df_cleaned_optimized_train.copy()\n\n# Encode categorical variables\nlabel_encoder = LabelEncoder()\n\n# Apply LabelEncoder to each categorical variable\nfor col in ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Age_Bucket']:\n    train_df[col] = label_encoder.fit_transform(train_df[col])\n    \n# Encode categorical variables\nlabel_encoder = LabelEncoder()\ntrain_df['Gender'] = label_encoder.fit_transform(train_df['Gender'])\ntrain_df['Vehicle_Age'] = label_encoder.fit_transform(train_df['Vehicle_Age'])\ntrain_df['Vehicle_Damage'] = label_encoder.fit_transform(train_df['Vehicle_Damage'])\n#df_cleaned_optimized_train['Age_Bucket'] = label_encoder.fit_transform(df_cleaned_optimized_train['Age_Bucket'])\n    \n# Viewing dataset\nlabel_encoder","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:32.157408Z","iopub.execute_input":"2024-07-21T06:12:32.157768Z","iopub.status.idle":"2024-07-21T06:12:45.420263Z","shell.execute_reply.started":"2024-07-21T06:12:32.15773Z","shell.execute_reply":"2024-07-21T06:12:45.419285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We applied the Label Encoder to the categorical variables, transforming them into numerical values. This transformation resulted in the creation of a new feature called 'Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Age_Bucket'. The encoding process is essential because many machine learning algorithms require input variables to be numerical to function correctly.\n\nThe 'Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Age_Bucket' variable will be used as an alternative to the original Transported variable. By transforming categorical variables into numerical ones, we ensure that the model can interpret and process this data effectively. This is particularly important for non-ordinal categorical variables, where each category is converted into a distinct number without implying an order.\n\nAdditionally, the new 'Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Age_Bucket' feature will allow us to evaluate whether this transformation positively influences the performance of the predictive models. By comparing the results obtained using the original variable and the transformed variable, we can determine which approach offers better predictions. This process is part of a broader feature engineering strategy aimed at optimizing input data to improve the accuracy and robustness of machine learning models.","metadata":{}},{"cell_type":"code","source":"# # Delete the 'Name' column\ntrain_df.drop(columns=['id'], inplace=True)\n\n# View the first DataFrame records after column deletion\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:45.421533Z","iopub.execute_input":"2024-07-21T06:12:45.421827Z","iopub.status.idle":"2024-07-21T06:12:45.733944Z","shell.execute_reply.started":"2024-07-21T06:12:45.421801Z","shell.execute_reply":"2024-07-21T06:12:45.733032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into feature set (X) and target variable (y)\n\n# Resources\nX1 = train_df.drop(columns=['Response'])  \n\n# Target variable\ny2 = train_df['Response']  ","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:45.735241Z","iopub.execute_input":"2024-07-21T06:12:45.735614Z","iopub.status.idle":"2024-07-21T06:12:46.031341Z","shell.execute_reply.started":"2024-07-21T06:12:45.735579Z","shell.execute_reply":"2024-07-21T06:12:46.030522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we performed the essential preprocessing step of splitting the target column, named Transported, for our machine learning model. This step is crucial to ensure that the model is trained properly, distinguishing between the data representing the classes we are trying to predict. Additionally, during this process, we applied class balancing techniques, ensuring that the model is trained fairly and evenly, regardless of the data distribution. By splitting the target column, we are preparing the data appropriately for the model to learn from them effectively, thus enabling accurate and reliable predictions.","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train1, X_test1, y_train2, y_test2 = train_test_split(X1, y2, test_size=0.2, random_state=42)\n\n# Viewing rows and columns\nprint(\"Shape of X_train1:\", X_train1.shape)\nprint(\"Shape of y_train2:\", y_train2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:46.032421Z","iopub.execute_input":"2024-07-21T06:12:46.03269Z","iopub.status.idle":"2024-07-21T06:12:48.463866Z","shell.execute_reply.started":"2024-07-21T06:12:46.032661Z","shell.execute_reply":"2024-07-21T06:12:48.462856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we conducted the training of the model using a train-test split. We adopted an 80/20 division, where 80% of the data was used for training and the remaining 20% was reserved for testing. This procedure is crucial for accurately evaluating the model's performance. The training set allows the model to learn patterns and relationships within the data, while the test set, which the model has not seen during training, is used to validate its ability to generalize and predict new data. Additionally, this approach helps identify and mitigate issues such as overfitting, ensuring that the model not only memorizes the training data but also performs well on unseen data.","metadata":{}},{"cell_type":"code","source":"# Converting categorical columns to dummy variables\nX_train1 = pd.get_dummies(X_train1)\nX_test1 = pd.get_dummies(X_test1)\n\n# Viewing rows and columns\nprint(\"Shape of X_train1:\", X_train1.shape)\nprint(\"Shape of y_train2:\", X_test1.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:48.465288Z","iopub.execute_input":"2024-07-21T06:12:48.465661Z","iopub.status.idle":"2024-07-21T06:12:51.743169Z","shell.execute_reply.started":"2024-07-21T06:12:48.465627Z","shell.execute_reply":"2024-07-21T06:12:51.742246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the LightGBM machine learning model, in addition to the initial preprocessing option, we performed an additional transformation using Pandas to convert categorical variables into numeric ones. This simple transformation is crucial to ensure that the model can interpret and utilize all data features properly, including those expressed as categories. Leveraging the power of Pandas, we were able to perform this conversion efficiently and effectively, maintaining data integrity and enabling the model to make accurate predictions based on a wide range of information. This step adds a layer of refinement to the data preparation process, contributing to the overall robustness and performance of the model.","metadata":{}},{"cell_type":"markdown","source":"## **Model 1 - LightGBM**","metadata":{}},{"cell_type":"code","source":"%%time\n# Importing library\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\n\n# Creating LGBM model\nlgbm_model = LGBMClassifier(device='gpu', \n                            num_leaves=31, \n                            max_depth=100, \n                            learning_rate=0.1, \n                            n_estimators=100)\n\n# Model training\nlgbm_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:51.744413Z","iopub.execute_input":"2024-07-21T06:12:51.744713Z","iopub.status.idle":"2024-07-21T06:12:54.133751Z","shell.execute_reply.started":"2024-07-21T06:12:51.744686Z","shell.execute_reply":"2024-07-21T06:12:54.1328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we utilized the LightGBM model, which achieved an accuracy score of 84.54%. LightGBM is known for its efficiency and scalability in handling large and complex datasets, making it a powerful tool for machine learning tasks. This model was meticulously trained and fine-tuned to capture subtle nuances in the data and generate accurate and reliable predictions. The high accuracy score obtained during model evaluation validates the robustness of our approach and underscores the predictive capability of LightGBM. This performance highlights its potential as a valuable tool for data analysis and prediction.","metadata":{}},{"cell_type":"code","source":"# LGBM model prediction\nlgbm_model_pred = lgbm_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:54.135164Z","iopub.execute_input":"2024-07-21T06:12:54.135754Z","iopub.status.idle":"2024-07-21T06:12:54.423069Z","shell.execute_reply.started":"2024-07-21T06:12:54.135727Z","shell.execute_reply":"2024-07-21T06:12:54.42218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Score model\nprint(\"Score model LightGBM:\", lgbm_model.score(X_train, y_train))","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:54.42441Z","iopub.execute_input":"2024-07-21T06:12:54.424865Z","iopub.status.idle":"2024-07-21T06:12:55.63797Z","shell.execute_reply.started":"2024-07-21T06:12:54.424831Z","shell.execute_reply":"2024-07-21T06:12:55.637034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the importance of features\n# Importância das features\n# Importância das features\nimportance = lgbm_model.feature_importances_\nfeature_names = X_train.columns\n\n# Ordenando pela importância\nindices = np.argsort(importance)\n\n# Limitando o número de features a serem exibidas\nnum_features = 30  # Número de features a serem exibidas\ntop_indices = indices[-num_features:]\n\n# Plotando a importância das features\nplt.figure(figsize=(20, 10))\nplt.title('Feature Importance')\nplt.barh(range(len(top_indices)), importance[top_indices], align='center')\nplt.yticks(range(len(top_indices)), [feature_names[i] for i in top_indices])\nplt.xlabel('Relative Importance')\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:55.639344Z","iopub.execute_input":"2024-07-21T06:12:55.639745Z","iopub.status.idle":"2024-07-21T06:12:56.280371Z","shell.execute_reply.started":"2024-07-21T06:12:55.639707Z","shell.execute_reply":"2024-07-21T06:12:56.2794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance Explanation\n\nThe provided plot illustrates the feature importance for the `LGBMClassifier` model. Feature importance is a measure of the contribution each feature makes to the prediction of the target variable. Higher values indicate greater importance.\n\n#### Observations:\n\n1. **Top Features**:\n   - **Age**: This is the most important feature, indicating that the age of the individual significantly impacts the model's predictions.\n   - **Annual_Premium**: The total annual premium amount is also highly influential in the model.\n   - **id**: The identifier has a high importance, which might suggest some encoded information or inherent ordering that affects the prediction.\n   - **Vintage**: The age of the policy is another crucial feature influencing the model.\n   - **Vehicle_Damage**: Whether the vehicle was damaged plays an important role in the model's decisions.\n   - **Vehicle_Age**: The age of the vehicle is also a significant factor.\n\n2. **Policy Sales Channels**:\n   - Several `Policy_Sales_Channel` features appear in the list, indicating that the channel through which the policy was sold impacts the prediction.\n   - **Policy_Sales_Channel_152.0**, **Policy_Sales_Channel_156.0**, **Policy_Sales_Channel_160.0**, **Policy_Sales_Channel_26.0**, and **Policy_Sales_Channel_157.0** are notable channels.\n\n3. **Previously_Insured**:\n   - Both `Previously_Insured_0` and `Previously_Insured_1` are important, suggesting that the model considers whether the customer was previously insured.\n\n4. **Region Codes**:\n   - Multiple `Region_Code` features are present, indicating that the geographic region of the customer also plays a role in the model's predictions.\n\n5. **Gender**:\n   - Gender has a lower but still notable importance, suggesting some influence on the model's predictions.\n\n### Key Takeaways:\n\n- **High Impact Features**: Age and Annual_Premium are the most influential features, meaning these aspects are critical in determining the likelihood of a positive response.\n- **Policy Sales Channels**: The presence of multiple policy sales channels highlights the significance of the method or channel through which the policy was sold.\n- **Geographic and Demographic Factors**: Region codes and gender also contribute, indicating that geographic and demographic factors affect the prediction.\n\n### Recommendations:\n\n- **Feature Engineering**: Further investigate the high importance of `id` to understand if it represents an encoded variable that might be split into more informative features.\n- **Channel Strategy**: Consider the impact of different sales channels and potentially refine marketing strategies based on the channels with higher importance.\n- **Geographic Insights**: Utilize the information from `Region_Code` features to develop region-specific strategies or understand regional differences in responses.\n","metadata":{}},{"cell_type":"code","source":"# Calculate model accuracy\naccuracy = accuracy_score(y_test, lgbm_model_pred)\nprint(\"Accuracy model - LightGBM:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:56.281729Z","iopub.execute_input":"2024-07-21T06:12:56.282144Z","iopub.status.idle":"2024-07-21T06:12:56.303768Z","shell.execute_reply.started":"2024-07-21T06:12:56.282106Z","shell.execute_reply":"2024-07-21T06:12:56.302812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, the LightGBM model achieved an accuracy of 77.91%. This metric is the result of a comprehensive process of model training and tuning, which included advanced preprocessing techniques, feature selection, and hyperparameter optimization. Additionally, we applied cross-validation to ensure the robustness of the results and prevent overfitting. This score reflects the effectiveness of LightGBM in addressing the challenges of the dataset, capturing complex patterns, and producing reliable predictions. Such accuracy is crucial for practical applications, such as risk prediction or data-driven decision-making.","metadata":{}},{"cell_type":"code","source":"# Create the confusion matrix\nconf_matrix2 = confusion_matrix(y_test, lgbm_model_pred)\n\n# Confusion matrix plot\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix - LGBM Classifier')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:56.305462Z","iopub.execute_input":"2024-07-21T06:12:56.305908Z","iopub.status.idle":"2024-07-21T06:12:56.570913Z","shell.execute_reply.started":"2024-07-21T06:12:56.305871Z","shell.execute_reply":"2024-07-21T06:12:56.569971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix Details\n\nThe matrix represents the performance of the `LGBMClassifier` model on the test dataset. Here's the breakdown of the confusion matrix:\n\n- **True Negatives (TN)**: 66,651\n  - These are the instances where the actual class was \"Not Transported\" and the model also predicted \"Not Transported\".\n  \n- **False Positives (FP)**: 48\n  - These are the instances where the actual class was \"Not Transported\" but the model predicted \"Transported\".\n  \n- **False Negatives (FN)**: 9,500\n  - These are the instances where the actual class was \"Transported\" but the model predicted \"Not Transported\".\n  \n- **True Positives (TP)**: 23\n  - These are the instances where the actual class was \"Transported\" and the model also predicted \"Transported\".\n  \n### Metrics Calculation\n\nBased on these values, we can calculate various performance metrics:\n\n1. **Accuracy**:\n   $$\n   \\text{Accuracy} = \\frac{\\text{TN} + \\text{TP}}{\\text{TN} + \\text{FP} + \\text{FN} + \\text{TP}} = \\frac{66,651 + 23}{66,651 + 48 + 9,500 + 23} = \\frac{66,674}{76,222} \\approx 0.874\n   $$\n\n2. **Precision** (for the positive class \"Transported\"):\n   $$\n   \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} = \\frac{23}{23 + 48} \\approx 0.324\n   $$\n\n3. **Recall** (Sensitivity, for the positive class \"Transported\"):\n   $$\n   \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{23}{23 + 9,500} \\approx 0.0024\n   $$\n\n4. **F1 Score** (for the positive class \"Transported\"):\n   $$\n   \\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\cdot \\frac{0.324 \\cdot 0.0024}{0.324 + 0.0024} \\approx 0.0048\n   $$\n\n5. **Specificity** (for the negative class \"Not Transported\"):\n   $$\n   \\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} = \\frac{66,651}{66,651 + 48} \\approx 0.999\n   $$\n\n### Interpretation\n\n- The accuracy of the model is relatively high at approximately 87.4%. However, accuracy can be misleading in imbalanced datasets.\n- The precision for the \"Transported\" class is quite low, indicating that when the model predicts \"Transported,\" it is correct about 32.4% of the time.\n- The recall for the \"Transported\" class is extremely low, indicating that the model is missing a large number of \"Transported\" cases.\n- The F1 score, which considers both precision and recall, is also very low, suggesting poor performance for the \"Transported\" class.\n- The specificity is very high, meaning the model is very good at identifying \"Not Transported\" cases correctly.\n\n### Conclusion\n\nThe model has a high ability to correctly identify \"Not Transported\" cases but struggles significantly with correctly identifying \"Transported\" cases. This indicates a potential issue with class imbalance or model bias towards the majority class (\"Not Transported\"). Further steps could include rebalancing the dataset, using different metrics for model evaluation, or trying other algorithms better suited for imbalanced datasets.\n","metadata":{}},{"cell_type":"code","source":"# ROC curve\ny_pred_proba = lgbm_model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\nprint(\"Area under the ROC curve LGBM (AUC):\", auc)\n\n# Plotagem da curva ROC\nplt.plot(fpr, tpr, label='ROC curve - LGBM (area = %0.2f)' % auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Curva ROC - LGBM')\nplt.legend(loc=\"lower right\")\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:56.57225Z","iopub.execute_input":"2024-07-21T06:12:56.572609Z","iopub.status.idle":"2024-07-21T06:12:57.184726Z","shell.execute_reply.started":"2024-07-21T06:12:56.572573Z","shell.execute_reply":"2024-07-21T06:12:57.183781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC Curve Explanation\n\nThe provided ROC (Receiver Operating Characteristic) curve is a graphical representation of the performance of the `LGBMClassifier` model. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n\n#### Key Components of the ROC Curve:\n\n1. **True Positive Rate (TPR)**:\n   - Also known as sensitivity or recall.\n   - Represents the proportion of actual positives correctly identified by the model.\n   - Formula: $ \\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n\n2. **False Positive Rate (FPR)**:\n   - Represents the proportion of actual negatives incorrectly identified as positives by the model.\n   - Formula: $ \\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} $\n\n3. **Diagonal Line (Baseline)**:\n   - The diagonal line (dashed) represents the performance of a random classifier.\n   - Any point along this line indicates that the classifier is performing no better than random guessing.\n\n4. **ROC Curve**:\n   - The blue curve represents the performance of the `LGBMClassifier` model across different threshold values.\n   - The closer the curve follows the left-hand border and then the top border of the ROC space, the better the model's performance.\n\n5. **AUC (Area Under the Curve)**:\n   - The area under the ROC curve (AUC) is a single scalar value that summarizes the performance of the model.\n   - AUC ranges from 0 to 1, with a higher value indicating better model performance.\n   - An AUC of 0.86 means that there is an 86% chance that the model will distinguish between a randomly chosen positive instance and a randomly chosen negative instance.\n\n### Interpretation of the ROC Curve for `LGBMClassifier`:\n\n- **Model Performance**:\n  - The ROC curve for the `LGBMClassifier` (blue curve) shows that the model performs well, as it stays above the diagonal baseline and close to the top left corner of the plot.\n  - The AUC score of 0.86 indicates that the model has a good ability to discriminate between the positive and negative classes.\n\n- **Threshold Selection**:\n  - The ROC curve helps in selecting the optimal threshold for classification. Depending on the business requirement, you might want to maximize TPR (sensitivity) while keeping FPR low.\n\n### Summary:\n\n- **High AUC Score**: The model has a strong discriminative power with an AUC of 0.86.\n- **Effective Classifier**: The curve's proximity to the top left corner indicates that the `LGBMClassifier` is effective at distinguishing between positive and negative instances.\n- **Threshold Decision**: The ROC curve provides insights into the trade-offs between TPR and FPR for different thresholds, aiding in the selection of the most appropriate threshold based on the specific use case.\n","metadata":{}},{"cell_type":"code","source":"# classification report model\nclass_report = classification_report(y_test, lgbm_model_pred)\nprint(\"Classification report - LGBM Classifier\")\nprint(class_report)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:57.185932Z","iopub.execute_input":"2024-07-21T06:12:57.186264Z","iopub.status.idle":"2024-07-21T06:12:57.388522Z","shell.execute_reply.started":"2024-07-21T06:12:57.186236Z","shell.execute_reply":"2024-07-21T06:12:57.387614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report Analysis\n\nThe provided classification report gives a detailed breakdown of the performance metrics for the `LGBMClassifier` model on the test dataset. Here is a detailed interpretation of the results:\n\n#### Model Performance Metrics:\n\n- **Accuracy**: 0.87\n  - The overall accuracy of the model, given by the formula:\n    $$\n    \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n    $$\n  - This indicates that the model correctly predicted approximately 87% of the instances in the test dataset.\n\n#### Detailed Classification Report:\n\nThe classification report breaks down the performance of the model for each class:\n\n1. **Class 0 (Not Transported)**:\n   - **Precision**: 0.88\n     - This means that 88% of the instances predicted as \"Not Transported\" were correctly classified.\n   - **Recall**: 1.00\n     - This indicates that the model identified all actual \"Not Transported\" instances correctly.\n   - **F1-Score**: 0.93\n     - The F1-score is the harmonic mean of precision and recall, given by the formula:\n       $$\n       F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n       $$\n     - For this class, the F1-score is 0.93.\n   - **Support**: 66,699\n     - The number of actual instances of \"Not Transported\" in the dataset.\n\n2. **Class 1 (Transported)**:\n   - **Precision**: 0.32\n     - This indicates that only 32% of the instances predicted as \"Transported\" were correctly classified.\n   - **Recall**: 0.00\n     - This means the model failed to identify any actual \"Transported\" instances correctly.\n   - **F1-Score**: 0.00\n     - The F1-score is 0 because both precision and recall are very low.\n   - **Support**: 9,523\n     - The number of actual instances of \"Transported\" in the dataset.\n\n#### Overall Metrics:\n\n- **Accuracy**: 0.87\n  - The overall accuracy of the model is consistent with the classification report, showing that 87% of all instances were correctly classified.\n\n- **Macro Average**:\n  - **Precision**: 0.60\n    - The unweighted average of precision for all classes.\n  - **Recall**: 0.50\n    - The unweighted average of recall for all classes.\n  - **F1-Score**: 0.47\n    - The unweighted average of F1-scores for all classes, showing a moderate overall performance.\n\n- **Weighted Average**:\n  - **Precision**: 0.81\n    - The average precision weighted by the number of instances in each class.\n  - **Recall**: 0.87\n    - The average recall weighted by the number of instances in each class.\n  - **F1-Score**: 0.82\n    - The average F1-score weighted by the number of instances in each class, indicating good overall performance despite the poor performance on the minority class.\n\n### Summary:\n\n- The model performs well in predicting the majority class (Not Transported) but struggles significantly with the minority class (Transported).\n- The high recall and precision for the majority class indicate that the model is highly confident and accurate in identifying instances of the majority class.\n- The poor performance on the minority class suggests that the model may be biased towards the majority class, likely due to class imbalance.\n- The overall accuracy and weighted averages are high, but the macro averages reveal the poor performance on the minority class, highlighting the need for addressing class imbalance.\n\n### Recommendations:\n\n- **Class Imbalance Handling**: Consider techniques such as oversampling the minority class, undersampling the majority class, or using different evaluation metrics that account for class imbalance.\n- **Model Tuning**: Experiment with different models, hyperparameters, or threshold adjustments to improve the recall and precision for the minority class.\n- **Feature Engineering**: Investigate additional features or different feature transformations that might help the model better distinguish between the classes.\n","metadata":{}},{"cell_type":"markdown","source":"## **Modelo 2 - XGBoost**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# XGBoost Model\n# Parameter tree_method='gpu_hist' for XGBoost GPU\nmodel_XGBoost = XGBClassifier(tree_method='gpu_hist', random_state=42)\nmodel_XGBoost_fit = model_XGBoost.fit(X_train, y_train)\nmodel_XGBoost","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:12:57.389575Z","iopub.execute_input":"2024-07-21T06:12:57.389849Z","iopub.status.idle":"2024-07-21T06:13:07.702697Z","shell.execute_reply.started":"2024-07-21T06:12:57.389823Z","shell.execute_reply":"2024-07-21T06:13:07.701797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Score model\nprint(\"Score model XGBoost:\", model_XGBoost.score(X_train, y_train))","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:07.703592Z","iopub.execute_input":"2024-07-21T06:13:07.703843Z","iopub.status.idle":"2024-07-21T06:13:16.470502Z","shell.execute_reply.started":"2024-07-21T06:13:07.703821Z","shell.execute_reply":"2024-07-21T06:13:16.469557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost model prediction\nxgboost_model_pred = model_XGBoost.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:16.471832Z","iopub.execute_input":"2024-07-21T06:13:16.472201Z","iopub.status.idle":"2024-07-21T06:13:18.679676Z","shell.execute_reply.started":"2024-07-21T06:13:16.472167Z","shell.execute_reply":"2024-07-21T06:13:18.678877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate model accuracy\naccuracy = accuracy_score(y_test, xgboost_model_pred)\nprint(\"Accuracy model - XGBoost:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:18.680804Z","iopub.execute_input":"2024-07-21T06:13:18.681123Z","iopub.status.idle":"2024-07-21T06:13:18.69864Z","shell.execute_reply.started":"2024-07-21T06:13:18.681094Z","shell.execute_reply":"2024-07-21T06:13:18.697794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the confusion matrix\nconf_matrix2 = confusion_matrix(y_test, xgboost_model_pred)\n\n# Confusion matrix plot\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix2, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix - XGBoost')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:18.699894Z","iopub.execute_input":"2024-07-21T06:13:18.700251Z","iopub.status.idle":"2024-07-21T06:13:18.965089Z","shell.execute_reply.started":"2024-07-21T06:13:18.700217Z","shell.execute_reply":"2024-07-21T06:13:18.964152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix Explanation\n\nThe provided confusion matrix for the `XGBoost` model gives insight into the performance of the model on the test dataset. Here is a detailed interpretation of the results:\n\n#### Components of the Confusion Matrix:\n\n- **True Negatives (TN)**: 66,651\n  - These are the instances where the actual class was \"Not Transported\" (0) and the model also predicted \"Not Transported\" (0).\n  \n- **False Positives (FP)**: 48\n  - These are the instances where the actual class was \"Not Transported\" (0) but the model predicted \"Transported\" (1).\n\n- **False Negatives (FN)**: 9,500\n  - These are the instances where the actual class was \"Transported\" (1) but the model predicted \"Not Transported\" (0).\n\n- **True Positives (TP)**: 23\n  - These are the instances where the actual class was \"Transported\" (1) and the model also predicted \"Transported\" (1).\n\n### Metrics Derived from the Confusion Matrix:\n\nUsing the values from the confusion matrix, we can derive several key performance metrics for the `XGBoost`:\n\n1. **Accuracy**:\n   $$\n   \\text{Accuracy} = \\frac{\\text{TN} + \\text{TP}}{\\text{TN} + \\text{FP} + \\text{FN} + \\text{TP}} = \\frac{66,651 + 23}{66,651 + 48 + 9,500 + 23} = \\frac{66,674}{76,222} \\approx 0.874\n   $$\n   - This indicates that the model correctly classified approximately 87.4% of the instances.\n\n2. **Precision** (for the positive class \"Transported\"):\n   $$\n   \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} = \\frac{23}{23 + 48} \\approx 0.324\n   $$\n   - Precision measures the accuracy of positive predictions. Here, about 32.4% of the instances predicted as \"Transported\" are actually \"Transported\".\n\n3. **Recall** (Sensitivity or True Positive Rate for the positive class \"Transported\"):\n   $$\n   \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{23}{23 + 9,500} \\approx 0.0024\n   $$\n   - Recall measures the model's ability to correctly identify actual positive instances. Here, the model correctly identifies about 0.24% of the \"Transported\" instances.\n\n4. **F1 Score**:\n   $$\n   \\text{F1 Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\cdot \\frac{0.324 \\cdot 0.0024}{0.324 + 0.0024} \\approx 0.0048\n   $$\n   - The F1 score is the harmonic mean of precision and recall, providing a balance between the two metrics.\n\n5. **Specificity** (for the negative class \"Not Transported\"):\n   $$\n   \\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} = \\frac{66,651}{66,651 + 48} \\approx 0.999\n   $$\n   - Specificity measures the model's ability to correctly identify actual negative instances. Here, the model correctly identifies about 99.9% of the \"Not Transported\" instances.\n\n### Interpretation:\n\n- **Model Performance**:\n  - The model performs well in predicting the majority class (Not Transported) but struggles significantly with the minority class (Transported).\n  - The high recall and precision for the majority class indicate that the model is highly confident and accurate in identifying instances of the majority class.\n  - The poor performance on the minority class suggests that the model may be biased towards the majority class, likely due to class imbalance.\n\n- **Overall Metrics**:\n  - The overall accuracy is high at 87.4%, but this can be misleading in imbalanced datasets.\n  - The precision for the \"Transported\" class is low at 32.4%, indicating that a significant number of instances predicted as \"Transported\" are actually \"Not Transported\".\n  - The recall for the \"Transported\" class is extremely low at 0.24%, indicating that the model misses a large number of actual \"Transported\" instances.\n  - The F1 score for the \"Transported\" class is very low, reflecting poor performance in identifying this class.\n  - The high specificity of 99.9% indicates that the model is very good at identifying \"Not Transported\" instances correctly.\n\n### Recommendations:\n\n- **Class Imbalance Handling**: Consider techniques such as oversampling the minority class, undersampling the majority class, or using different evaluation metrics that account for class imbalance.\n- **Model Tuning**: Experiment with different models, hyperparameters, or threshold adjustments to improve the recall and precision for the minority class.\n- **Feature Engineering**: Investigate additional features or different feature transformations that might help the model better distinguish between the classes.\n","metadata":{}},{"cell_type":"code","source":"# ROC curve\ny_pred_proba = model_XGBoost.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nauc = roc_auc_score(y_test, y_pred_proba)\nprint(\"Area under the ROC curve (AUC):\", auc)\n\n# Plotagem da curva ROC\nplt.plot(fpr, tpr, label='ROC curve XGBoost (area = %0.2f)' % auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Curva ROC - XGBoost')\nplt.legend(loc=\"lower right\")\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:18.966331Z","iopub.execute_input":"2024-07-21T06:13:18.966606Z","iopub.status.idle":"2024-07-21T06:13:21.440897Z","shell.execute_reply.started":"2024-07-21T06:13:18.966581Z","shell.execute_reply":"2024-07-21T06:13:21.439992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC Curve Explanation\n\nThe provided ROC (Receiver Operating Characteristic) curve is a graphical representation of the performance of the `XGBoost` model. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n\n#### Key Components of the ROC Curve:\n\n1. **True Positive Rate (TPR)**:\n   - Also known as sensitivity or recall.\n   - Represents the proportion of actual positives correctly identified by the model.\n   - Formula: $ \\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n\n2. **False Positive Rate (FPR)**:\n   - Represents the proportion of actual negatives incorrectly identified as positives by the model.\n   - Formula: $ \\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} $\n\n3. **Diagonal Line (Baseline)**:\n   - The diagonal line (dashed) represents the performance of a random classifier.\n   - Any point along this line indicates that the classifier is performing no better than random guessing.\n\n4. **ROC Curve**:\n   - The green curve represents the performance of the `XGBoost` model across different threshold values.\n   - The closer the curve follows the left-hand border and then the top border of the ROC space, the better the model's performance.\n\n5. **AUC (Area Under the Curve)**:\n   - The area under the ROC curve (AUC) is a single scalar value that summarizes the performance of the model.\n   - AUC ranges from 0 to 1, with a higher value indicating better model performance.\n   - An AUC of 0.86 means that there is an 86% chance that the model will distinguish between a randomly chosen positive instance and a randomly chosen negative instance.\n\n### Interpretation of the ROC Curve for `XGBoost`:\n\n- **Model Performance**:\n  - The ROC curve for the `XGBoost` (green curve) shows that the model performs well, as it stays above the diagonal baseline and close to the top left corner of the plot.\n  - The AUC score of 0.86 indicates that the model has a good ability to discriminate between the positive and negative classes.\n\n- **Threshold Selection**:\n  - The ROC curve helps in selecting the optimal threshold for classification. Depending on the business requirement, you might want to maximize TPR (sensitivity) while keeping FPR low.\n\n### Summary:\n\n- **High AUC Score**: The model has a strong discriminative power with an AUC of 0.86.\n- **Effective Classifier**: The curve's proximity to the top left corner indicates that the `XGBoost` is effective at distinguishing between positive and negative instances.\n- **Threshold Decision**: The ROC curve provides insights into the trade-offs between TPR and FPR for different thresholds, aiding in the selection of the most appropriate threshold based on the specific use case.\n","metadata":{}},{"cell_type":"code","source":"# Classification report model\nclass_report = classification_report(y_test, xgboost_model_pred)\nprint(\"Classification report - XGBoost Classifier\")\nprint(class_report)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:21.44215Z","iopub.execute_input":"2024-07-21T06:13:21.442435Z","iopub.status.idle":"2024-07-21T06:13:21.634179Z","shell.execute_reply.started":"2024-07-21T06:13:21.442409Z","shell.execute_reply":"2024-07-21T06:13:21.63326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification Report Analysis\n\nThe provided classification report gives a detailed breakdown of the performance metrics for the `XGBoost` model on the test dataset. Here is a detailed interpretation of the results:\n\n#### Model Performance Metrics:\n\n- **Accuracy**: 0.87\n\n  - The overall accuracy of the model, given by the formula:\n  \n    $$\n    \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n    $$\n    \n  - This indicates that the model correctly predicted approximately 87% of the instances in the test dataset.\n\n#### Detailed Classification Report:\n\nThe classification report breaks down the performance of the model for each class:\n\n1. **Class 0 (Not Transported)**:\n   - **Precision**: 0.88\n   \n     - This means that 88% of the instances predicted as \"Not Transported\" were correctly classified.\n     \n   - **Recall**: 1.00\n   \n     - This indicates that the model identified all actual \"Not Transported\" instances correctly.\n     \n   - **F1-Score**: 0.93\n   \n     - The F1-score is the harmonic mean of precision and recall, given by the formula:\n     \n       $$\n       F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n       $$\n       \n     - For this class, the F1-score is 0.93.\n     \n   - **Support**: 66,699\n     - The number of actual instances of \"Not Transported\" in the dataset.\n\n2. **Class 1 (Transported)**:\n   - **Precision**: 0.47\n     - This indicates that only 47% of the instances predicted as \"Transported\" were correctly classified.\n   - **Recall**: 0.02\n     - This means the model correctly identified 2% of actual \"Transported\" instances.\n   - **F1-Score**: 0.03\n     - The F1-score is low because both precision and recall are low.\n   - **Support**: 9,523\n     - The number of actual instances of \"Transported\" in the dataset.\n\n#### Overall Metrics:\n\n- **Accuracy**: 0.87\n  - The overall accuracy of the model is consistent with the classification report, showing that 87% of all instances were correctly classified.\n\n- **Macro Average**:\n  - **Precision**: 0.67\n    - The unweighted average of precision for all classes.\n  - **Recall**: 0.51\n    - The unweighted average of recall for all classes.\n  - **F1-Score**: 0.48\n    - The unweighted average of F1-scores for all classes, showing a moderate overall performance.\n\n- **Weighted Average**:\n  - **Precision**: 0.83\n    - The average precision weighted by the number of instances in each class.\n  - **Recall**: 0.87\n    - The average recall weighted by the number of instances in each class.\n  - **F1-Score**: 0.82\n    - The average F1-score weighted by the number of instances in each class, indicating good overall performance despite the poor performance on the minority class.\n\n### Summary:\n\n- The model performs well in predicting the majority class (Not Transported) but struggles significantly with the minority class (Transported).\n- The high recall and precision for the majority class indicate that the model is highly confident and accurate in identifying instances of the majority class.\n- The poor performance on the minority class suggests that the model may be biased towards the majority class, likely due to class imbalance.\n- The overall accuracy and weighted averages are high, but the macro averages reveal the poor performance on the minority class, highlighting the need for addressing class imbalance.\n\n### Recommendations:\n\n- **Class Imbalance Handling**: Consider techniques such as oversampling the minority class, undersampling the majority class, or using different evaluation metrics that account for class imbalance.\n- **Model Tuning**: Experiment with different models, hyperparameters, or threshold adjustments to improve the recall and precision for the minority class.\n- **Feature Engineering**: Investigate additional features or different feature transformations that might help the model better distinguish between the classes.\n","metadata":{}},{"cell_type":"markdown","source":"# Part 13 - Model result","metadata":{}},{"cell_type":"code","source":"# Models to be evaluated\nmodels = [\n          GaussianNB(),  # Naive Bayes Model\n          DecisionTreeClassifier(random_state=42),  # Decision Tree Model\n          RandomForestClassifier(n_estimators=100, random_state=42),  # Random forest model\n          LogisticRegression(random_state=50),  # Logistic regression model\n          AdaBoostClassifier(random_state=45),  # Ada Boost Model\n          XGBClassifier(),  # XGBoost Model Parameter tree_method='gpu_hist' for XGBoost GPU\n          LGBMClassifier()  # LightGBM Model Parameter device='gpu' for LightGBM GPU\n         ]\n\n# List to store results\nresults = []\n\n# Evaluate each model\nfor i, model in enumerate(models):\n    model.fit(X_train, y_train)\n    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n    \n    # Store results in dictionary\n    results.append({'Model': type(model).__name__,\n                    'Training Accuracy': train_accuracy,\n                    'Testing Accuracy': test_accuracy})\n\n# Convert results list to DataFrame\nresults_df = pd.DataFrame(results)\n\n# Function to highlight the maximum value in a column\ndef highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]\n\n# Apply the highlight function to the 'Testing Accuracy' column\nresults_df.style.apply(highlight_max, subset=['Testing Accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:13:21.635413Z","iopub.execute_input":"2024-07-21T06:13:21.63574Z","iopub.status.idle":"2024-07-21T06:17:05.524445Z","shell.execute_reply.started":"2024-07-21T06:13:21.635713Z","shell.execute_reply":"2024-07-21T06:17:05.523459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Results Summary\n\nThe results of the models shown in the image highlight the training and testing accuracies for each evaluated model. Here is a summary of the results for each model:\n\n1. **GaussianNB (Naive Bayes)**\n   - **Training Accuracy**: 0.877191\n   - **Testing Accuracy**: 0.874210\n\n2. **DecisionTreeClassifier (Decision Tree)**\n   - **Training Accuracy**: 1.000000\n   - **Testing Accuracy**: 0.826100\n\n3. **RandomForestClassifier (Random Forest)**\n   - **Training Accuracy**: 0.999980\n   - **Testing Accuracy**: 0.868791\n\n4. **LogisticRegression (Logistic Regression)**\n   - **Training Accuracy**: 0.878030\n   - **Testing Accuracy**: 0.875062\n\n5. **AdaBoostClassifier**\n   - **Training Accuracy**: 0.877945\n   - **Testing Accuracy**: 0.875062\n\n6. **XGBClassifier (XGBoost)**\n   - **Training Accuracy**: 0.880356\n   - **Testing Accuracy**: 0.874419\n\n7. **LGBMClassifier (LightGBM)**\n   - **Training Accuracy**: 0.878161\n   - **Testing Accuracy**: 0.874603\n\n### Interpretation\n\n- **GaussianNB**: The training and testing accuracies are quite close, indicating good overall performance with little to no evidence of overfitting.\n- **DecisionTreeClassifier**: Shows perfect training accuracy (1.000000) but a significant drop in testing accuracy, suggesting possible overfitting.\n- **RandomForestClassifier**: Presents high training accuracy and good testing accuracy, indicating a good balance between bias and variance.\n- **LogisticRegression**: Demonstrates consistent performance with very close training and testing accuracies.\n- **AdaBoostClassifier**: Has similar performance to Logistic Regression, with nearly identical training and testing accuracies.\n- **XGBClassifier**: Shows solid performance with high and very close training and testing accuracies, indicating a good model.\n- **LGBMClassifier**: Also shows good performance with high and very close training and testing accuracies.\n\n### Conclusion\n\n- **Best Overall Model**: The choice of the best model may depend on other factors beyond accuracy, such as recall, precision, F1-score, and the trade-off between bias and variance. However, based solely on testing accuracies, the models `LogisticRegression`, `AdaBoostClassifier`, `XGBClassifier`, and `LGBMClassifier` exhibit the best performances.\n","metadata":{}},{"cell_type":"code","source":"# Importing library for metrics machine learning models\nfrom sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n\n# Models to be evaluated\nmodels = [GaussianNB(),  # Naive Bayes Model\n          DecisionTreeClassifier(random_state=42),  # Decision Tree Model\n          RandomForestClassifier(n_estimators=100, random_state=42),  # Random forest model\n          LogisticRegression(random_state=50),  # Logistic regression model\n          AdaBoostClassifier(random_state=45),  # Ada Boost Model\n          XGBClassifier(),  # XGBoost Model\n          LGBMClassifier()  # LightGBM Model\n         ]\n\n# List to store results\nresults = []\n\n# Evaluate each model\nfor i, model in enumerate(models):\n    model.fit(X_train, y_train)\n    y_test_pred = model.predict(X_test)\n    \n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_precision = precision_score(y_test, y_test_pred, average='binary')\n    test_recall = recall_score(y_test, y_test_pred, average='binary')\n    test_f1 = f1_score(y_test, y_test_pred, average='binary')\n    test_support = y_test.shape[0]\n    \n    # Store results in dictionary\n    results.append({'Model': type(model).__name__,\n                    'Accuracy': test_accuracy,\n                    'Precision': test_precision,\n                    'Recall': test_recall,\n                    'F1-Score': test_f1,\n                    'Support': test_support}\n                  )\n\n# Convert results list to DataFrame\nresults_df = pd.DataFrame(results)\n\n# Function to highlight the maximum value in each column\ndef highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' \n            if v \n            else '' \n            for v in is_max]\n\n# Apply the highlight function to the DataFrame\nstyled_results_df = results_df.style.apply(highlight_max, subset=['Accuracy', \n                                                                  'Precision', \n                                                                  'Recall', \n                                                                  'F1-Score'])\n\n# Display the styled DataFrame\nstyled_results_df","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:17:05.52583Z","iopub.execute_input":"2024-07-21T06:17:05.526217Z","iopub.status.idle":"2024-07-21T06:20:21.383099Z","shell.execute_reply.started":"2024-07-21T06:17:05.526183Z","shell.execute_reply":"2024-07-21T06:20:21.382102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Results Summary\n\nThe results of the models shown in the image highlight the metrics for each evaluated model. Here is a summary of the results for each model:\n\n1. **GaussianNB (Naive Bayes)**\n   - **Accuracy**: 0.874210\n   - **Precision**: 0.190476\n   - **Recall**: 0.002100\n   - **F1-Score**: 0.004155\n   - **Support**: 76222\n\n2. **DecisionTreeClassifier (Decision Tree)**\n   - **Accuracy**: 0.826100\n   - **Precision**: 0.302832\n   - **Recall**: 0.309056\n   - **F1-Score**: 0.301891\n   - **Support**: 76222\n\n3. **RandomForestClassifier (Random Forest)**\n   - **Accuracy**: 0.868791\n   - **Precision**: 0.393208\n   - **Recall**: 0.092408\n   - **F1-Score**: 0.149647\n   - **Support**: 76222\n\n4. **LogisticRegression (Logistic Regression)**\n   - **Accuracy**: 0.875062\n   - **Precision**: 0.000000\n   - **Recall**: 0.000000\n   - **F1-Score**: 0.000000\n   - **Support**: 76222\n\n5. **AdaBoostClassifier**\n   - **Accuracy**: 0.875062\n   - **Precision**: 0.500000\n   - **Recall**: 0.000022\n   - **F1-Score**: 0.000045\n   - **Support**: 76222\n\n6. **XGBClassifier (XGBoost)**\n   - **Accuracy**: 0.874419\n   - **Precision**: 0.433243\n   - **Recall**: 0.016696\n   - **F1-Score**: 0.032154\n   - **Support**: 76222\n\n7. **LGBMClassifier (LightGBM)**\n   - **Accuracy**: 0.874603\n   - **Precision**: 0.253521\n   - **Recall**: 0.001890\n   - **F1-Score**: 0.003752\n   - **Support**: 76222\n\n### Interpretation\n\n- **GaussianNB**: Shows low precision, recall, and F1-score despite a relatively high accuracy. This indicates poor performance in identifying the positive class.\n- **DecisionTreeClassifier**: Has a good balance between precision, recall, and F1-score compared to other models, though it shows signs of overfitting.\n- **RandomForestClassifier**: Presents a moderate precision but low recall and F1-score, indicating it misses many positive instances.\n- **LogisticRegression**: Exhibits poor performance in precision, recall, and F1-score, suggesting it struggles to identify the positive class.\n- **AdaBoostClassifier**: Shows the highest precision but very low recall and F1-score, indicating it identifies positive instances accurately but misses many.\n- **XGBClassifier**: Demonstrates a high precision but low recall and F1-score, indicating it identifies some positive instances accurately but misses many.\n- **LGBMClassifier**: Shows moderate precision but very low recall and F1-score, indicating it misses many positive instances.\n\n### Conclusion\n\n- **Best Overall Model**: Based on the metrics provided, `AdaBoostClassifier` shows the highest precision. However, it is important to consider the balance between precision, recall, and F1-score for the overall model performance. `DecisionTreeClassifier` offers a better balance between these metrics compared to other models.\n","metadata":{}},{"cell_type":"markdown","source":"# 2) Section - Submission","metadata":{}},{"cell_type":"markdown","source":"# Part 14 - LightGBM Submission kaggle ","metadata":{}},{"cell_type":"markdown","source":"In step 14 of the submission process for Kaggle, I am using the LightGBM model, which has shown excellent accuracy. To ensure data integrity and avoid issues with the original dataset, I am taking specific precautions. Firstly, I am segmenting the model into different parts and ensuring careful data handling. Additionally, I am loading the entire dataset into the model, allowing for a more comprehensive and detailed analysis. This approach not only improves accuracy but also ensures that the model is robust and reliable when handling real data in a production environment.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the datasets\ntrain_df = pd.read_csv('/kaggle/input/playground-series-s4e7/train.csv')\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e7/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s4e7/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:23:18.910144Z","iopub.execute_input":"2024-07-21T06:23:18.911006Z","iopub.status.idle":"2024-07-21T06:23:44.906463Z","shell.execute_reply.started":"2024-07-21T06:23:18.910972Z","shell.execute_reply":"2024-07-21T06:23:44.90559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handle missing values\ntrain_df = train_df.fillna(-1)\ntest_df = test_df.fillna(-1)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:23:44.908192Z","iopub.execute_input":"2024-07-21T06:23:44.908518Z","iopub.status.idle":"2024-07-21T06:23:52.461298Z","shell.execute_reply.started":"2024-07-21T06:23:44.908487Z","shell.execute_reply":"2024-07-21T06:23:52.460258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode categorical variables\nlabel_encoders = {}\nfor column in train_df.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    train_df[column] = le.fit_transform(train_df[column])\n    test_df[column] = le.transform(test_df[column])\n    label_encoders[column] = le\n\n# Viewing\nle","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:23:52.462501Z","iopub.execute_input":"2024-07-21T06:23:52.462806Z","iopub.status.idle":"2024-07-21T06:24:06.521871Z","shell.execute_reply.started":"2024-07-21T06:23:52.462778Z","shell.execute_reply":"2024-07-21T06:24:06.521003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate resources and target\nX = train_df.drop(columns=['id', 'Response'])\ny = train_df['Response']\nX_test = test_df.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:24:06.524153Z","iopub.execute_input":"2024-07-21T06:24:06.524467Z","iopub.status.idle":"2024-07-21T06:24:07.082016Z","shell.execute_reply.started":"2024-07-21T06:24:06.52444Z","shell.execute_reply":"2024-07-21T06:24:07.081189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting training and validation data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:24:07.083091Z","iopub.execute_input":"2024-07-21T06:24:07.0834Z","iopub.status.idle":"2024-07-21T06:24:09.733986Z","shell.execute_reply.started":"2024-07-21T06:24:07.083372Z","shell.execute_reply":"2024-07-21T06:24:09.733006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set model parameters for GPU\nparams = {'objective': 'binary',\n          'boosting_type': 'gbdt',\n          'num_leaves': 31,\n          'learning_rate': 0.05,\n          'feature_fraction': 0.9,\n          'n_estimators': 100,\n          'device': 'gpu',\n          'gpu_platform_id': 0,\n          'gpu_device_id': 0,\n          'metric': 'auc'}\n\n# Create the LightGBM datasets\ntrain_data = lgb.Dataset(X_train, label=y_train)\nval_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n\n# Train the LightGBM model\nlgbm_model = lgb.train(params,\n                       train_data,\n                       valid_sets=[val_data])\n\n# Viewing model\nlgbm_model","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:24:09.735121Z","iopub.execute_input":"2024-07-21T06:24:09.735395Z","iopub.status.idle":"2024-07-21T06:25:02.181244Z","shell.execute_reply.started":"2024-07-21T06:24:09.735371Z","shell.execute_reply":"2024-07-21T06:25:02.179656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ny_test_pred = lgbm_model.predict(X_test, num_iteration=lgbm_model.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:25:02.18244Z","iopub.execute_input":"2024-07-21T06:25:02.182906Z","iopub.status.idle":"2024-07-21T06:25:17.464321Z","shell.execute_reply.started":"2024-07-21T06:25:02.182877Z","shell.execute_reply":"2024-07-21T06:25:17.462914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the length of test data and predictions\nprint(f\"Test set length: {len(test_df)}\")\nprint(f\"Prediction length: {len(y_test_pred)}\")\n\n# Prepare the submission file\nif len(test_df) == len(y_test_pred):\n    submission = pd.DataFrame({'id': test_df['id'],'Response': y_test_pred})\n    submission.to_csv('submission2.csv', index=False)\nelse:\n    print(\"Error: The length of test data and predictions do not match.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:25:17.474246Z","iopub.execute_input":"2024-07-21T06:25:17.475077Z","iopub.status.idle":"2024-07-21T06:25:39.748514Z","shell.execute_reply.started":"2024-07-21T06:25:17.475037Z","shell.execute_reply":"2024-07-21T06:25:39.747468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viewing dataset\njf = pd.read_csv(\"/kaggle/working/submission2.csv\")\n\n# Viewing first 10 data\njf.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-21T06:26:22.124281Z","iopub.execute_input":"2024-07-21T06:26:22.124981Z","iopub.status.idle":"2024-07-21T06:26:24.626369Z","shell.execute_reply.started":"2024-07-21T06:26:22.124935Z","shell.execute_reply":"2024-07-21T06:26:24.625409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}